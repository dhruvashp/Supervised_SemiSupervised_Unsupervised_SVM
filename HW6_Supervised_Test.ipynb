{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW6 \n",
    "\n",
    "Supervised Monte Carlo iterations = 1, mock example case\n",
    "\n",
    "\n",
    "Based on the C-Range selected in the previous portion, we will now use that range to perform a single Monte-Carlo Iteration\n",
    "\n",
    "Doing this just a single time helps us with a few things :\n",
    "\n",
    "Repeating can be done easily by just adding an external loop\n",
    "We can get an overall sense, idea of the code workings over just a single Monte-Carlo Iteration\n",
    "Various one time results can be obtained in this test case with the Monte-Carlo iteration case focusing more on the 'cumulative' performance scores\n",
    "\n",
    "C Range is 10^-1 to 10^7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0    0.007675  0.007111  0.051206  0.475626  0.000044  0.000065  0.000098   \n",
      "1    0.017425  0.023832  0.110188  0.669121  0.000106  0.000048  0.000019   \n",
      "2    0.010449  0.014722  0.069250  0.552095  0.000073  0.000092  0.000148   \n",
      "3    0.019843  0.038944  0.126141  0.590068  0.000219  0.000170  0.000018   \n",
      "4    0.012577  0.011691  0.084037  0.577521  0.000088  0.000175  0.000170   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "449  0.021543  0.041537  0.136327  0.577915  0.000256  0.000183  0.000000   \n",
      "450  0.011022  0.013085  0.072670  0.661867  0.000057  0.000074  0.000105   \n",
      "451  0.017363  0.019220  0.111276  0.617599  0.000134  0.000113  0.000063   \n",
      "452  0.016406  0.023998  0.104639  0.600502  0.000126  0.000087  0.000040   \n",
      "453  0.014179  0.019271  0.091652  0.649252  0.000091  0.000080  0.000065   \n",
      "\n",
      "           X8        X9       X10  ...       X21       X22       X23  \\\n",
      "0    0.000050  0.000079  0.000024  ...  0.010472  0.010339  0.068523   \n",
      "1    0.000024  0.000206  0.000078  ...  0.018084  0.028332  0.114618   \n",
      "2    0.000074  0.000138  0.000039  ...  0.012819  0.019701  0.083554   \n",
      "3    0.000040  0.000517  0.000143  ...  0.022833  0.047193  0.146224   \n",
      "4    0.000080  0.000207  0.000058  ...  0.014815  0.015643  0.102566   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "449  0.000000  0.000490  0.000175  ...  0.025085  0.056238  0.157884   \n",
      "450  0.000058  0.000112  0.000033  ...  0.011738  0.017161  0.080056   \n",
      "451  0.000050  0.000242  0.000099  ...  0.019549  0.025686  0.124178   \n",
      "452  0.000023  0.000257  0.000084  ...  0.018701  0.034050  0.119572   \n",
      "453  0.000047  0.000142  0.000055  ...  0.015266  0.027156  0.099071   \n",
      "\n",
      "          X24       X25       X26       X27       X28       X29       X30  \n",
      "0    0.874463  0.000056  0.000151  0.000267  0.000088  0.000143  0.000036  \n",
      "1    0.723234  0.000118  0.000066  0.000031  0.000040  0.000266  0.000083  \n",
      "2    0.825104  0.000100  0.000218  0.000343  0.000113  0.000217  0.000052  \n",
      "3    0.775826  0.000285  0.000275  0.000042  0.000093  0.000651  0.000163  \n",
      "4    0.804216  0.000114  0.000488  0.000517  0.000196  0.000383  0.000082  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "449  0.781899  0.000360  0.000323  0.000000  0.000000  0.000603  0.000219  \n",
      "450  0.740232  0.000071  0.000136  0.000216  0.000103  0.000145  0.000043  \n",
      "451  0.767134  0.000214  0.000277  0.000288  0.000126  0.000415  0.000131  \n",
      "452  0.781389  0.000173  0.000240  0.000201  0.000074  0.000386  0.000113  \n",
      "453  0.747178  0.000116  0.000132  0.000162  0.000097  0.000226  0.000063  \n",
      "\n",
      "[454 rows x 30 columns]\n",
      "0      1\n",
      "1      0\n",
      "2      1\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "449    0\n",
      "450    1\n",
      "451    0\n",
      "452    0\n",
      "453    0\n",
      "Name: y, Length: 454, dtype: int32\n",
      "           X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0    0.017871  0.033696  0.116794  0.664131  0.000103  0.000159  0.000118   \n",
      "1    0.009693  0.009083  0.063554  0.572089  0.000052  0.000072  0.000081   \n",
      "2    0.010822  0.012125  0.070601  0.546133  0.000065  0.000076  0.000063   \n",
      "3    0.011224  0.013559  0.072883  0.635710  0.000046  0.000054  0.000068   \n",
      "4    0.013309  0.012469  0.086072  0.601378  0.000090  0.000081  0.000075   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "110  0.015269  0.017923  0.097971  0.645888  0.000093  0.000071  0.000029   \n",
      "111  0.016814  0.018723  0.108421  0.620185  0.000153  0.000125  0.000053   \n",
      "112  0.013218  0.013200  0.084959  0.598843  0.000079  0.000070  0.000041   \n",
      "113  0.016103  0.022718  0.104805  0.601617  0.000135  0.000169  0.000077   \n",
      "114  0.020896  0.033768  0.134116  0.653368  0.000181  0.000164  0.000089   \n",
      "\n",
      "           X8        X9       X10  ...       X21       X22       X23  \\\n",
      "0    0.000044  0.000178  0.000099  ...  0.018643  0.042580  0.129563   \n",
      "1    0.000047  0.000095  0.000029  ...  0.011886  0.014315  0.076145   \n",
      "2    0.000040  0.000125  0.000042  ...  0.013381  0.016975  0.086656   \n",
      "3    0.000036  0.000110  0.000033  ...  0.012267  0.015334  0.080147   \n",
      "4    0.000040  0.000159  0.000051  ...  0.015299  0.015737  0.099043   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "110  0.000023  0.000209  0.000063  ...  0.016552  0.022541  0.110596   \n",
      "111  0.000039  0.000231  0.000092  ...  0.018737  0.021968  0.121084   \n",
      "112  0.000032  0.000136  0.000053  ...  0.015466  0.016057  0.102270   \n",
      "113  0.000037  0.000231  0.000086  ...  0.018429  0.030061  0.123767   \n",
      "114  0.000050  0.000340  0.000137  ...  0.022057  0.044889  0.144768   \n",
      "\n",
      "          X24       X25       X26       X27       X28       X29       X30  \n",
      "0    0.724344  0.000130  0.000477  0.000432  0.000162  0.000325  0.000139  \n",
      "1    0.813416  0.000076  0.000187  0.000216  0.000113  0.000179  0.000039  \n",
      "2    0.828268  0.000088  0.000150  0.000188  0.000082  0.000188  0.000055  \n",
      "3    0.762356  0.000055  0.000122  0.000157  0.000057  0.000147  0.000041  \n",
      "4    0.786867  0.000112  0.000176  0.000227  0.000084  0.000240  0.000064  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "110  0.747941  0.000123  0.000234  0.000150  0.000078  0.000371  0.000086  \n",
      "111  0.766037  0.000212  0.000227  0.000226  0.000103  0.000387  0.000112  \n",
      "112  0.788785  0.000109  0.000180  0.000193  0.000112  0.000278  0.000073  \n",
      "113  0.780451  0.000185  0.000467  0.000417  0.000127  0.000366  0.000145  \n",
      "114  0.727911  0.000298  0.000457  0.000363  0.000170  0.000548  0.000193  \n",
      "\n",
      "[115 rows x 30 columns]\n",
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "110    0\n",
      "111    0\n",
      "112    0\n",
      "113    0\n",
      "114    0\n",
      "Name: y, Length: 115, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('wdbc.csv', header = None)\n",
    "\n",
    "\n",
    "output = df.iloc[:,0]\n",
    "\n",
    "\n",
    "for i in np.arange(0,df.shape[0]):\n",
    "    if output.iloc[i] == 'B':\n",
    "        output.iloc[i] = 0\n",
    "    else:\n",
    "        output.iloc[i] = 1\n",
    "\n",
    "\n",
    "\n",
    "features = df.iloc[:,1:]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "features_normal = normalize(features)\n",
    "\n",
    "\n",
    "features_normal_df = pd.DataFrame(features_normal)\n",
    "\n",
    "\n",
    "norm_whole = pd.concat([features_normal_df,output],axis=1)\n",
    "\n",
    "\n",
    "col_head = norm_whole.columns\n",
    "\n",
    "\n",
    "norm_whole.columns= ['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10','X11','X12','X13','X14','X15','X16','X17','X18','X19','X20','X21','X22','X23','X24','X25','X26','X27','X28','X29','X30','y']\n",
    "\n",
    "\n",
    "norm_whole.sort_values(by=['y'],inplace=True)\n",
    "\n",
    "\n",
    "norm_whole.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "X_y_0 = norm_whole.iloc[0:357,:]\n",
    "X_y_1 = norm_whole.iloc[357:569,:]\n",
    "X_y_1.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_y_train_0,X_y_test_0 = train_test_split(X_y_0,test_size = 0.2,shuffle=True)\n",
    "X_y_train_1,X_y_test_1 = train_test_split(X_y_1,test_size = 0.2,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "X_y_train = pd.concat([X_y_train_0,X_y_train_1],axis=0)\n",
    "X_y_test = pd.concat([X_y_test_0,X_y_test_1],axis=0)\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_y_train = shuffle(X_y_train)\n",
    "X_y_test = shuffle(X_y_test)\n",
    "\n",
    "\n",
    "\n",
    "X_y_train.reset_index(drop=True,inplace=True)\n",
    "X_y_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "X_train = X_y_train.drop(columns=['y'])\n",
    "X_test = X_y_test.drop(columns=['y'])\n",
    "y_train = X_y_train['y'].astype(int)\n",
    "y_test =  X_y_test['y'].astype(int)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed previously, this section of the code has now generated X_train,X_test,y_train,y_test with the following deliberations :\n",
    "\n",
    "They are normalized, feature wise (whole set, ONCE, initially)\n",
    "They are randomly selected from the normalized set\n",
    "The test has 20 % of both the positive and negative classes\n",
    "After combining positive and negative classes, selected randomly, for train and test, from positive and negative class subsets of the original dataset, in the consequential proportions, we've shuffled them once more so that positive classes don't appear in a continuous arrangement after the negative classes (or vice versa), and thus positive and negative classes in train and test both, appear randomly, but still contain the classes in a required proportion as mentioned.\n",
    "\n",
    "Thus they have the needed positive and negative class proportion in test, are randomly selected, and have normalized features.\n",
    "\n",
    "Further explanation of this code section given previously"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting final penalty parameter using 5-fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Estimated Test Errors\n",
      "0.1                      21.3773\n",
      "1.0                       7.9243\n",
      "10.0                     7.48962\n",
      "100.0                    5.50183\n",
      "1000.0                   4.84737\n",
      "10000.0                  3.74847\n",
      "100000.0                  4.8547\n",
      "1000000.0                4.40781\n",
      "10000000.0               5.73382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold  # Stratified KFold may be used. Class imbalance doesn't seem severe, at least from the outset, currently, and thus simple KFold has been used. As such using Stratified KFold only minorly modifies the code\n",
    "from sklearn.svm import LinearSVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")   # For a few values of C, over a few folds, convergence didn't occur and output window was flooded with warnings, to avoid this we've used this code\n",
    "\n",
    "kf = KFold(n_splits=5,shuffle=True)\n",
    "\n",
    "C = np.array([10**(-1),10**(0),10**(1),10**(2),10**(3),10**(4),10**(5),10**(6),10**(7)])  # Selected a priori\n",
    "\n",
    "# For a given C, all 5 folds will be run at a time. Thus different C's may have different folds (mostly should), but due to\n",
    "# 'averaging' this shouldn't affect comparative results\n",
    "\n",
    "error_df = pd.DataFrame(index = C, columns = ['Estimated Test Errors'])\n",
    "\n",
    "for i in np.arange(0,C.size):\n",
    "    \n",
    "    cv_ite = -1\n",
    "    cv_error_vector = np.zeros(5)   # Corresponding to CV iterations\n",
    "    \n",
    "    for train,test in kf.split(X_train):\n",
    "        \n",
    "        cv_ite = cv_ite + 1  # CV iteration count (0,1,2,3,4 for 1,2,3,4,5 fold iterations)\n",
    "        X_train_cv,X_test_cv = X_train.iloc[train,:],X_train.iloc[test,:]\n",
    "        y_train_cv,y_test_cv = y_train[train],y_train[test]\n",
    "        clf = LinearSVC(penalty='l1',dual=False,C=C[i]).fit(X_train_cv,y_train_cv)\n",
    "        y_test_cv_pred = clf.predict(X_test_cv)\n",
    "        \n",
    "        mis = 0\n",
    "        for l in np.arange(0,X_test_cv.shape[0]):\n",
    "            if y_test_cv_pred[l] != y_test_cv.iloc[l]:\n",
    "                mis = mis + 1\n",
    "        \n",
    "        percent_error = (mis/X_test_cv.shape[0])*100\n",
    "        cv_error_vector[cv_ite] = percent_error\n",
    "        \n",
    "    \n",
    "    error_df.iloc[i,0] = np.mean(cv_error_vector)\n",
    "\n",
    "\n",
    "print(error_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting C which gives minimum test error estimate \n",
    "(Note : 10,000 was the most frequent over a few runs. In Monte-Carlo, we can pick a measure of central tendency over all the runs, here we'll automatically select the C which gives minimum error. In Monte-Carlo also we do the same, only difference being we record which C is selected for each Monte-Carlo iteration, then pick an 'averaged C' using a measure of central tendency (mode may be used here))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum test error estimate obtained is thus : \n",
      " 3.7484737484737485 %\n",
      "The C for which this minimum test error is obtained is thus : \n",
      " 10000.0\n"
     ]
    }
   ],
   "source": [
    "min_error = np.min(error_df.to_numpy().flatten())\n",
    "min_C = C[np.argmin(error_df.to_numpy().flatten())]\n",
    "\n",
    "print('The minimum test error estimate obtained is thus : \\n',min_error,'%')\n",
    "print('The C for which this minimum test error is obtained is thus : \\n',min_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using min_C, X_train, X_test, y_train, y_test for various scores (as asked in the question)\n",
    "\n",
    "(These scores, will be then averaged over all Monte-Carlo iterations, once it is performed in the next part)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual Test Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual test error, for minimizing C is obtained : \n",
      " 4.3478260869565215 %\n"
     ]
    }
   ],
   "source": [
    "clf_final = LinearSVC(penalty='l1',dual=False,C=min_C).fit(X_train,y_train)\n",
    "y_test_pred = clf_final.predict(X_test)\n",
    "\n",
    "mis = 0\n",
    "for l in np.arange(0,X_test.shape[0]):\n",
    "    if y_test_pred[l] != y_test.iloc[l]:\n",
    "        mis = mis + 1\n",
    "\n",
    "test_error = (mis/X_test.shape[0])*100\n",
    "print('The actual test error, for minimizing C is obtained : \\n',test_error,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, Precision, Recall, F1 Score (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error, for minimizing C is obtained : \n",
      " 1.9823788546255507 %\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = clf_final.predict(X_train)\n",
    "\n",
    "mis = 0\n",
    "for l in np.arange(0,X_train.shape[0]):\n",
    "    if y_train_pred[l] != y_train.iloc[l]:\n",
    "        mis = mis + 1\n",
    "\n",
    "train_error = (mis/X_train.shape[0])*100\n",
    "print('The training error, for minimizing C is obtained : \\n',train_error,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for training is : \n",
      " [[282   3]\n",
      " [  6 163]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix_train = confusion_matrix(y_train,y_train_pred)\n",
    "\n",
    "print('The confusion matrix for training is : \\n',confusion_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for train, appropriately indexed is : \n",
      "             Predicted 0  Predicted 1\n",
      "Actually 0          282            3\n",
      "Actually 1            6          163\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_train_df = pd.DataFrame(confusion_matrix_train,index=['Actually 0','Actually 1'],columns=['Predicted 0','Predicted 1'])\n",
    "print('The confusion matrix for train, appropriately indexed is : \\n',confusion_matrix_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision for train is : \n",
      " 98.19277108433735 %\n",
      "The recall for train is : \n",
      " 96.44970414201184 %\n"
     ]
    }
   ],
   "source": [
    "precision_train = (confusion_matrix_train[1][1]/(confusion_matrix_train[1][1]+confusion_matrix_train[0][1]))*100\n",
    "recall_train = (confusion_matrix_train[1][1]/(confusion_matrix_train[1][1]+confusion_matrix_train[1][0]))*100\n",
    "\n",
    "print('The precision for train is : \\n',precision_train,'%')\n",
    "print('The recall for train is : \\n',recall_train,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for training is : \n",
      " 98.01762114537445 %\n",
      "The f1 score for training is : \n",
      " 0.973134328358209\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = ((confusion_matrix_train[0][0]+confusion_matrix_train[1][1])/(confusion_matrix_train[0][0]+confusion_matrix_train[1][1]+confusion_matrix_train[0][1]+confusion_matrix_train[1][0]))*100\n",
    "f1_train = ((2*(precision_train/100)*(recall_train/100))/((precision_train/100)+(recall_train/100))) # divided by 100 as precision and recall specified in percentage\n",
    "print('The accuracy for training is : \\n',accuracy_train,'%')\n",
    "print('The f1 score for training is : \\n',f1_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy, Precision, Recall, F1 Score (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for test is : \n",
      " [[68  4]\n",
      " [ 1 42]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_test = confusion_matrix(y_test,y_test_pred)\n",
    "\n",
    "print('The confusion matrix for test is : \\n',confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for test, appropriately indexed is : \n",
      "             Predicted 0  Predicted 1\n",
      "Actually 0           68            4\n",
      "Actually 1            1           42\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_test_df = pd.DataFrame(confusion_matrix_test,index=['Actually 0','Actually 1'],columns=['Predicted 0','Predicted 1'])\n",
    "print('The confusion matrix for test, appropriately indexed is : \\n',confusion_matrix_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision for test is : \n",
      " 91.30434782608695 %\n",
      "The recall for test is : \n",
      " 97.67441860465115 %\n"
     ]
    }
   ],
   "source": [
    "precision_test = (confusion_matrix_test[1][1]/(confusion_matrix_test[1][1]+confusion_matrix_test[0][1]))*100\n",
    "recall_test = (confusion_matrix_test[1][1]/(confusion_matrix_test[1][1]+confusion_matrix_test[1][0]))*100\n",
    "\n",
    "print('The precision for test is : \\n',precision_test,'%')\n",
    "print('The recall for test is : \\n',recall_test,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for test is : \n",
      " 95.65217391304348 %\n",
      "The f1 score for test is : \n",
      " 0.9438202247191011\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = ((confusion_matrix_test[0][0]+confusion_matrix_test[1][1])/(confusion_matrix_test[0][0]+confusion_matrix_test[1][1]+confusion_matrix_test[0][1]+confusion_matrix_test[1][0]))*100\n",
    "f1_test = ((2*(precision_test/100)*(recall_test/100))/((precision_test/100)+(recall_test/100))) # divided by 100 as precision and recall specified in percentage\n",
    "print('The accuracy for test is : \\n',accuracy_test,'%')\n",
    "print('The f1 score for test is : \\n',f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC and AUC for Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE : Probabilities are not available in LinearSVC, SVC does have Probabilities but does not have L1 Penalization\n",
    "Thus we will use CalibrateClassifierCV in sklearn to obtain probabilities using the decision_function of our clf_final (final optimized classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.19475125e-03 9.97805249e-01]\n",
      " [9.96826196e-01 3.17380404e-03]\n",
      " [7.80424122e-03 9.92195759e-01]\n",
      " [9.89412847e-01 1.05871532e-02]\n",
      " [8.43557597e-02 9.15644240e-01]\n",
      " [8.46308841e-01 1.53691159e-01]\n",
      " [3.69495632e-02 9.63050437e-01]\n",
      " [8.81198933e-01 1.18801067e-01]\n",
      " [9.99851943e-01 1.48057257e-04]\n",
      " [9.14301381e-01 8.56986187e-02]\n",
      " [9.31603811e-01 6.83961886e-02]\n",
      " [7.82525170e-02 9.21747483e-01]\n",
      " [9.57557807e-01 4.24421925e-02]\n",
      " [2.56678517e-03 9.97433215e-01]\n",
      " [9.97595407e-01 2.40459336e-03]\n",
      " [1.42115858e-01 8.57884142e-01]\n",
      " [4.13021243e-01 5.86978757e-01]\n",
      " [9.92222555e-01 7.77744481e-03]\n",
      " [9.96431491e-01 3.56850850e-03]\n",
      " [9.99442051e-01 5.57949419e-04]\n",
      " [4.38086757e-02 9.56191324e-01]\n",
      " [9.87022455e-01 1.29775450e-02]\n",
      " [9.99972218e-01 2.77822598e-05]\n",
      " [8.15784125e-01 1.84215875e-01]\n",
      " [9.99319710e-01 6.80290045e-04]\n",
      " [1.28885698e-03 9.98711143e-01]\n",
      " [6.59915994e-02 9.34008401e-01]\n",
      " [6.73612584e-01 3.26387416e-01]\n",
      " [1.06811521e-01 8.93188479e-01]\n",
      " [9.19346122e-01 8.06538781e-02]\n",
      " [4.18182684e-02 9.58181732e-01]\n",
      " [9.77028241e-01 2.29717587e-02]\n",
      " [3.23063968e-01 6.76936032e-01]\n",
      " [9.98831744e-01 1.16825581e-03]\n",
      " [9.94833794e-01 5.16620643e-03]\n",
      " [2.06578884e-02 9.79342112e-01]\n",
      " [7.84407789e-01 2.15592211e-01]\n",
      " [9.58108140e-01 4.18918597e-02]\n",
      " [7.60074122e-02 9.23992588e-01]\n",
      " [1.75842318e-01 8.24157682e-01]\n",
      " [6.75073575e-01 3.24926425e-01]\n",
      " [7.84595233e-01 2.15404767e-01]\n",
      " [9.76316974e-01 2.36830264e-02]\n",
      " [7.31078201e-01 2.68921799e-01]\n",
      " [2.56082590e-03 9.97439174e-01]\n",
      " [2.99786402e-02 9.70021360e-01]\n",
      " [9.80299001e-01 1.97009992e-02]\n",
      " [9.43289139e-02 9.05671086e-01]\n",
      " [8.89823752e-01 1.10176248e-01]\n",
      " [7.17023028e-02 9.28297697e-01]\n",
      " [9.99872598e-01 1.27401943e-04]\n",
      " [9.88187117e-01 1.18128834e-02]\n",
      " [8.58042014e-01 1.41957986e-01]\n",
      " [5.45141001e-03 9.94548590e-01]\n",
      " [9.93554548e-01 6.44545244e-03]\n",
      " [6.37051314e-02 9.36294869e-01]\n",
      " [1.69022441e-01 8.30977559e-01]\n",
      " [9.98770964e-01 1.22903560e-03]\n",
      " [9.98441665e-01 1.55833507e-03]\n",
      " [3.50993454e-02 9.64900655e-01]\n",
      " [8.20711988e-01 1.79288012e-01]\n",
      " [9.84940339e-01 1.50596611e-02]\n",
      " [5.33998359e-01 4.66001641e-01]\n",
      " [5.15147922e-01 4.84852078e-01]\n",
      " [9.40950299e-01 5.90497013e-02]\n",
      " [1.09712667e-01 8.90287333e-01]\n",
      " [4.98811846e-03 9.95011882e-01]\n",
      " [9.54240360e-01 4.57596399e-02]\n",
      " [9.30714569e-01 6.92854310e-02]\n",
      " [6.58853115e-02 9.34114689e-01]\n",
      " [9.81525775e-01 1.84742247e-02]\n",
      " [6.25254048e-01 3.74745952e-01]\n",
      " [2.38500253e-02 9.76149975e-01]\n",
      " [9.48894858e-04 9.99051105e-01]\n",
      " [9.90963239e-01 9.03676084e-03]\n",
      " [3.83416754e-02 9.61658325e-01]\n",
      " [2.07700527e-02 9.79229947e-01]\n",
      " [9.51458903e-01 4.85410974e-02]\n",
      " [2.06084738e-01 7.93915262e-01]\n",
      " [9.97061992e-01 2.93800821e-03]\n",
      " [3.87886294e-01 6.12113706e-01]\n",
      " [8.67275578e-01 1.32724422e-01]\n",
      " [9.77128545e-01 2.28714549e-02]\n",
      " [9.53994485e-01 4.60055148e-02]\n",
      " [8.66179335e-01 1.33820665e-01]\n",
      " [9.76361370e-01 2.36386296e-02]\n",
      " [9.99927815e-01 7.21851321e-05]\n",
      " [2.94258752e-01 7.05741248e-01]\n",
      " [1.50321508e-01 8.49678492e-01]\n",
      " [8.45795263e-01 1.54204737e-01]\n",
      " [6.12685989e-02 9.38731401e-01]\n",
      " [9.76660699e-01 2.33393011e-02]\n",
      " [1.45532568e-02 9.85446743e-01]\n",
      " [1.97444262e-01 8.02555738e-01]\n",
      " [1.81195265e-03 9.98188047e-01]\n",
      " [9.28195459e-01 7.18045406e-02]\n",
      " [3.36291026e-01 6.63708974e-01]\n",
      " [9.61131074e-01 3.88689256e-02]\n",
      " [5.39139177e-03 9.94608608e-01]\n",
      " [5.44100080e-02 9.45589992e-01]\n",
      " [7.48629331e-02 9.25137067e-01]\n",
      " [7.78979519e-01 2.21020481e-01]\n",
      " [9.17651985e-01 8.23480147e-02]\n",
      " [8.92125342e-01 1.07874658e-01]\n",
      " [1.22943243e-02 9.87705676e-01]\n",
      " [9.88981121e-01 1.10188794e-02]\n",
      " [9.80612749e-01 1.93872509e-02]\n",
      " [9.84358335e-01 1.56416653e-02]\n",
      " [1.10718194e-03 9.98892818e-01]\n",
      " [1.76334356e-02 9.82366564e-01]\n",
      " [9.95727587e-01 4.27241267e-03]\n",
      " [9.99991510e-01 8.48976422e-06]\n",
      " [9.70188304e-01 2.98116957e-02]\n",
      " [9.97389220e-01 2.61077994e-03]\n",
      " [9.92327108e-01 7.67289211e-03]\n",
      " [9.90605038e-01 9.39496202e-03]\n",
      " [9.98199961e-01 1.80003932e-03]\n",
      " [1.22856282e-02 9.87714372e-01]\n",
      " [9.86228398e-01 1.37716024e-02]\n",
      " [8.58309059e-01 1.41690941e-01]\n",
      " [9.22627516e-01 7.73724841e-02]\n",
      " [9.99905376e-01 9.46242903e-05]\n",
      " [9.70018984e-01 2.99810162e-02]\n",
      " [9.53423520e-01 4.65764804e-02]\n",
      " [9.96117085e-01 3.88291471e-03]\n",
      " [6.54611267e-02 9.34538873e-01]\n",
      " [9.76326902e-01 2.36730982e-02]\n",
      " [2.63218450e-01 7.36781550e-01]\n",
      " [8.42445033e-01 1.57554967e-01]\n",
      " [9.99465946e-01 5.34053890e-04]\n",
      " [9.95972474e-01 4.02752631e-03]\n",
      " [9.39574120e-01 6.04258803e-02]\n",
      " [9.43208639e-01 5.67913611e-02]\n",
      " [9.07199375e-01 9.28006252e-02]\n",
      " [5.17087590e-02 9.48291241e-01]\n",
      " [5.37191286e-03 9.94628087e-01]\n",
      " [9.97351977e-01 2.64802269e-03]\n",
      " [9.71550409e-01 2.84495915e-02]\n",
      " [1.21336096e-02 9.87866390e-01]\n",
      " [9.95435800e-01 4.56419953e-03]\n",
      " [4.44732448e-02 9.55526755e-01]\n",
      " [9.97208608e-01 2.79139174e-03]\n",
      " [3.27420856e-03 9.96725791e-01]\n",
      " [9.94290597e-01 5.70940323e-03]\n",
      " [2.60520829e-02 9.73947917e-01]\n",
      " [8.90662776e-01 1.09337224e-01]\n",
      " [9.13072566e-01 8.69274343e-02]\n",
      " [8.63171741e-01 1.36828259e-01]\n",
      " [9.66517992e-01 3.34820081e-02]\n",
      " [2.67143559e-02 9.73285644e-01]\n",
      " [7.77182370e-01 2.22817630e-01]\n",
      " [6.01359023e-01 3.98640977e-01]\n",
      " [9.52496159e-01 4.75038406e-02]\n",
      " [9.99463089e-01 5.36911461e-04]\n",
      " [8.43577961e-01 1.56422039e-01]\n",
      " [6.58654836e-01 3.41345164e-01]\n",
      " [9.14340704e-01 8.56592959e-02]\n",
      " [9.68410799e-01 3.15892010e-02]\n",
      " [9.93503940e-01 6.49606031e-03]\n",
      " [9.40352316e-01 5.96476841e-02]\n",
      " [9.99825231e-01 1.74768797e-04]\n",
      " [2.34251370e-01 7.65748630e-01]\n",
      " [5.46311978e-01 4.53688022e-01]\n",
      " [5.46472141e-02 9.45352786e-01]\n",
      " [9.98408902e-01 1.59109790e-03]\n",
      " [5.74127149e-01 4.25872851e-01]\n",
      " [5.68209572e-01 4.31790428e-01]\n",
      " [9.31407341e-03 9.90685927e-01]\n",
      " [9.87636307e-01 1.23636927e-02]\n",
      " [1.41887497e-02 9.85811250e-01]\n",
      " [6.76577426e-03 9.93234226e-01]\n",
      " [4.33815896e-02 9.56618410e-01]\n",
      " [9.82992138e-01 1.70078615e-02]\n",
      " [9.70030821e-01 2.99691792e-02]\n",
      " [3.36902821e-01 6.63097179e-01]\n",
      " [2.33417341e-04 9.99766583e-01]\n",
      " [8.80857412e-01 1.19142588e-01]\n",
      " [9.91422996e-01 8.57700372e-03]\n",
      " [9.81760678e-01 1.82393217e-02]\n",
      " [2.58236742e-02 9.74176326e-01]\n",
      " [1.90676877e-02 9.80932312e-01]\n",
      " [9.99158977e-01 8.41023258e-04]\n",
      " [2.33141614e-01 7.66858386e-01]\n",
      " [9.53941300e-01 4.60586997e-02]\n",
      " [3.06354555e-02 9.69364545e-01]\n",
      " [5.79516277e-02 9.42048372e-01]\n",
      " [9.96472830e-01 3.52717004e-03]\n",
      " [9.89126526e-01 1.08734739e-02]\n",
      " [6.55864074e-01 3.44135926e-01]\n",
      " [9.82991534e-01 1.70084657e-02]\n",
      " [9.53626630e-01 4.63733701e-02]\n",
      " [1.55404179e-01 8.44595821e-01]\n",
      " [8.49737510e-02 9.15026249e-01]\n",
      " [9.71936129e-01 2.80638706e-02]\n",
      " [8.96791201e-01 1.03208799e-01]\n",
      " [9.93895812e-01 6.10418764e-03]\n",
      " [3.19163614e-02 9.68083639e-01]\n",
      " [6.52853250e-01 3.47146750e-01]\n",
      " [1.76945142e-01 8.23054858e-01]\n",
      " [7.69182972e-03 9.92308170e-01]\n",
      " [6.58548647e-02 9.34145135e-01]\n",
      " [8.44668175e-01 1.55331825e-01]\n",
      " [3.51940408e-03 9.96480596e-01]\n",
      " [9.61695001e-01 3.83049989e-02]\n",
      " [1.18167065e-03 9.98818329e-01]\n",
      " [1.82410437e-05 9.99981759e-01]\n",
      " [9.68609527e-01 3.13904726e-02]\n",
      " [6.09079491e-02 9.39092051e-01]\n",
      " [7.55713023e-01 2.44286977e-01]\n",
      " [9.04512791e-01 9.54872090e-02]\n",
      " [9.91027833e-01 8.97216747e-03]\n",
      " [3.60024016e-02 9.63997598e-01]\n",
      " [9.95303599e-01 4.69640120e-03]\n",
      " [9.88616803e-01 1.13831970e-02]\n",
      " [4.84600418e-01 5.15399582e-01]\n",
      " [1.40256139e-01 8.59743861e-01]\n",
      " [1.19648815e-01 8.80351185e-01]\n",
      " [1.22901546e-02 9.87709845e-01]\n",
      " [9.81293745e-01 1.87062551e-02]\n",
      " [9.98867938e-01 1.13206227e-03]\n",
      " [9.89138900e-01 1.08611001e-02]\n",
      " [9.88760092e-01 1.12399082e-02]\n",
      " [9.98551237e-01 1.44876276e-03]\n",
      " [1.79599414e-03 9.98204006e-01]\n",
      " [9.99996826e-01 3.17385371e-06]\n",
      " [2.53693478e-02 9.74630652e-01]\n",
      " [9.23516927e-01 7.64830726e-02]\n",
      " [5.87434578e-02 9.41256542e-01]\n",
      " [9.92682186e-01 7.31781366e-03]\n",
      " [9.33950430e-02 9.06604957e-01]\n",
      " [9.99456287e-01 5.43712521e-04]\n",
      " [3.26842286e-02 9.67315771e-01]\n",
      " [7.89242576e-01 2.10757424e-01]\n",
      " [9.98025597e-01 1.97440267e-03]\n",
      " [1.29111292e-02 9.87088871e-01]\n",
      " [9.97174524e-01 2.82547607e-03]\n",
      " [9.33777463e-01 6.62225366e-02]\n",
      " [8.92184428e-01 1.07815572e-01]\n",
      " [7.04302773e-01 2.95697227e-01]\n",
      " [2.57038647e-01 7.42961353e-01]\n",
      " [9.77498403e-01 2.25015975e-02]\n",
      " [9.95672838e-01 4.32716217e-03]\n",
      " [9.16874979e-03 9.90831250e-01]\n",
      " [9.96070457e-01 3.92954263e-03]\n",
      " [4.18851513e-01 5.81148487e-01]\n",
      " [8.44889238e-03 9.91551108e-01]\n",
      " [1.12579606e-01 8.87420394e-01]\n",
      " [9.77914601e-01 2.20853991e-02]\n",
      " [1.11069860e-02 9.88893014e-01]\n",
      " [9.65967217e-01 3.40327832e-02]\n",
      " [9.50431834e-01 4.95681657e-02]\n",
      " [2.11229240e-02 9.78877076e-01]\n",
      " [2.43252370e-02 9.75674763e-01]\n",
      " [4.51009471e-01 5.48990529e-01]\n",
      " [7.08214516e-02 9.29178548e-01]\n",
      " [9.25702798e-01 7.42972016e-02]\n",
      " [9.99973481e-01 2.65191730e-05]\n",
      " [1.68266140e-01 8.31733860e-01]\n",
      " [3.54651762e-03 9.96453482e-01]\n",
      " [3.56530519e-03 9.96434695e-01]\n",
      " [6.30362793e-01 3.69637207e-01]\n",
      " [9.99585844e-01 4.14156069e-04]\n",
      " [9.99934481e-01 6.55193300e-05]\n",
      " [5.25307706e-01 4.74692294e-01]\n",
      " [8.02584550e-01 1.97415450e-01]\n",
      " [9.99240872e-01 7.59128431e-04]\n",
      " [9.94679682e-01 5.32031842e-03]\n",
      " [1.87934967e-02 9.81206503e-01]\n",
      " [2.27501009e-02 9.77249899e-01]\n",
      " [3.98950566e-04 9.99601049e-01]\n",
      " [9.99864420e-01 1.35579716e-04]\n",
      " [9.70634179e-01 2.93658214e-02]\n",
      " [8.75223591e-01 1.24776409e-01]\n",
      " [9.67828605e-01 3.21713945e-02]\n",
      " [8.69067497e-01 1.30932503e-01]\n",
      " [3.59701825e-03 9.96402982e-01]\n",
      " [9.38547841e-01 6.14521586e-02]\n",
      " [9.18871250e-01 8.11287500e-02]\n",
      " [4.79068295e-02 9.52093171e-01]\n",
      " [5.50260505e-02 9.44973949e-01]\n",
      " [9.81517605e-03 9.90184824e-01]\n",
      " [6.68556324e-01 3.31443676e-01]\n",
      " [8.35906365e-01 1.64093635e-01]\n",
      " [4.44264697e-01 5.55735303e-01]\n",
      " [5.71347668e-01 4.28652332e-01]\n",
      " [9.95522997e-01 4.47700303e-03]\n",
      " [3.31510963e-03 9.96684890e-01]\n",
      " [1.06962519e-02 9.89303748e-01]\n",
      " [9.99976026e-01 2.39740613e-05]\n",
      " [9.26903813e-01 7.30961871e-02]\n",
      " [6.05732591e-01 3.94267409e-01]\n",
      " [9.42707076e-01 5.72929244e-02]\n",
      " [2.75842266e-02 9.72415773e-01]\n",
      " [5.79904633e-02 9.42009537e-01]\n",
      " [7.63286042e-01 2.36713958e-01]\n",
      " [9.69414059e-01 3.05859407e-02]\n",
      " [9.99667265e-01 3.32735152e-04]\n",
      " [9.98755744e-01 1.24425619e-03]\n",
      " [9.00306440e-01 9.96935599e-02]\n",
      " [9.85690110e-01 1.43098902e-02]\n",
      " [2.06552613e-02 9.79344739e-01]\n",
      " [2.99403281e-02 9.70059672e-01]\n",
      " [9.83434376e-01 1.65656238e-02]\n",
      " [9.91648786e-01 8.35121402e-03]\n",
      " [9.98267233e-01 1.73276743e-03]\n",
      " [7.73470620e-01 2.26529380e-01]\n",
      " [9.99998293e-01 1.70668973e-06]\n",
      " [6.67597591e-03 9.93324024e-01]\n",
      " [9.96341594e-01 3.65840553e-03]\n",
      " [9.97021968e-01 2.97803246e-03]\n",
      " [7.78311263e-01 2.21688737e-01]\n",
      " [9.80934187e-01 1.90658128e-02]\n",
      " [9.70988327e-01 2.90116734e-02]\n",
      " [3.46756310e-02 9.65324369e-01]\n",
      " [9.58936410e-01 4.10635901e-02]\n",
      " [1.37051768e-02 9.86294823e-01]\n",
      " [7.93500404e-05 9.99920650e-01]\n",
      " [8.00187774e-01 1.99812226e-01]\n",
      " [3.74650212e-01 6.25349788e-01]\n",
      " [9.74178722e-01 2.58212781e-02]\n",
      " [9.99926294e-01 7.37063276e-05]\n",
      " [9.89468859e-01 1.05311409e-02]\n",
      " [7.12491903e-02 9.28750810e-01]\n",
      " [9.94035415e-01 5.96458474e-03]\n",
      " [1.68666903e-01 8.31333097e-01]\n",
      " [9.99271455e-01 7.28544895e-04]\n",
      " [9.85117509e-01 1.48824910e-02]\n",
      " [8.40385585e-01 1.59614415e-01]\n",
      " [8.95423974e-01 1.04576026e-01]\n",
      " [9.22379251e-01 7.76207488e-02]\n",
      " [9.34160675e-01 6.58393246e-02]\n",
      " [5.47444156e-02 9.45255584e-01]\n",
      " [9.75366063e-01 2.46339368e-02]\n",
      " [9.86031087e-01 1.39689131e-02]\n",
      " [9.55725136e-01 4.42748637e-02]\n",
      " [9.17157411e-01 8.28425890e-02]\n",
      " [9.85534131e-01 1.44658689e-02]\n",
      " [7.88375121e-01 2.11624879e-01]\n",
      " [9.96695950e-01 3.30405016e-03]\n",
      " [9.73279643e-01 2.67203574e-02]\n",
      " [3.63050346e-02 9.63694965e-01]\n",
      " [9.66439378e-01 3.35606221e-02]\n",
      " [9.43632242e-01 5.63677583e-02]\n",
      " [9.99567437e-01 4.32562592e-04]\n",
      " [6.89530655e-01 3.10469345e-01]\n",
      " [7.35089107e-01 2.64910893e-01]\n",
      " [2.76170324e-02 9.72382968e-01]\n",
      " [9.79226243e-01 2.07737566e-02]\n",
      " [3.80597261e-01 6.19402739e-01]\n",
      " [9.97290525e-01 2.70947508e-03]\n",
      " [9.99517847e-01 4.82152821e-04]\n",
      " [9.92566762e-01 7.43323802e-03]\n",
      " [9.44706299e-01 5.52937008e-02]\n",
      " [9.97264939e-01 2.73506055e-03]\n",
      " [9.88719452e-01 1.12805477e-02]\n",
      " [5.14900250e-01 4.85099750e-01]\n",
      " [9.50909268e-01 4.90907320e-02]\n",
      " [7.61402329e-01 2.38597671e-01]\n",
      " [9.76933815e-01 2.30661855e-02]\n",
      " [9.91040394e-01 8.95960609e-03]\n",
      " [6.92813666e-01 3.07186334e-01]\n",
      " [9.54689937e-01 4.53100631e-02]\n",
      " [9.94965849e-01 5.03415131e-03]\n",
      " [9.96683186e-01 3.31681414e-03]\n",
      " [8.51534602e-01 1.48465398e-01]\n",
      " [9.32119160e-03 9.90678808e-01]\n",
      " [3.63696418e-04 9.99636304e-01]\n",
      " [9.64836248e-03 9.90351638e-01]\n",
      " [1.13323285e-03 9.98866767e-01]\n",
      " [1.87586687e-02 9.81241331e-01]\n",
      " [9.69445042e-01 3.05549584e-02]\n",
      " [9.99873641e-01 1.26358656e-04]\n",
      " [9.10671476e-01 8.93285240e-02]\n",
      " [8.77020742e-01 1.22979258e-01]\n",
      " [7.85779369e-01 2.14220631e-01]\n",
      " [9.97325977e-01 2.67402344e-03]\n",
      " [9.99570917e-01 4.29082972e-04]\n",
      " [1.90254158e-01 8.09745842e-01]\n",
      " [9.77583603e-01 2.24163971e-02]\n",
      " [9.60131953e-01 3.98680471e-02]\n",
      " [9.90248783e-01 9.75121663e-03]\n",
      " [9.98378751e-01 1.62124852e-03]\n",
      " [8.31192708e-01 1.68807292e-01]\n",
      " [9.99455610e-01 5.44389868e-04]\n",
      " [1.89949907e-01 8.10050093e-01]\n",
      " [9.93720118e-01 6.27988194e-03]\n",
      " [9.78075214e-01 2.19247855e-02]\n",
      " [3.44467804e-02 9.65553220e-01]\n",
      " [2.80243993e-02 9.71975601e-01]\n",
      " [5.94255470e-02 9.40574453e-01]\n",
      " [6.58210112e-01 3.41789888e-01]\n",
      " [9.99918025e-01 8.19752417e-05]\n",
      " [9.98425466e-01 1.57453417e-03]\n",
      " [9.06029371e-01 9.39706291e-02]\n",
      " [6.22435829e-01 3.77564171e-01]\n",
      " [1.78669410e-02 9.82133059e-01]\n",
      " [2.26963194e-02 9.77303681e-01]\n",
      " [3.59878324e-03 9.96401217e-01]\n",
      " [9.98387375e-01 1.61262473e-03]\n",
      " [9.62623282e-01 3.73767179e-02]\n",
      " [1.35695663e-02 9.86430434e-01]\n",
      " [2.68685106e-02 9.73131489e-01]\n",
      " [3.61372976e-02 9.63862702e-01]\n",
      " [2.59162082e-01 7.40837918e-01]\n",
      " [9.24163071e-01 7.58369292e-02]\n",
      " [7.52099414e-01 2.47900586e-01]\n",
      " [9.80569258e-01 1.94307421e-02]\n",
      " [4.67588361e-03 9.95324116e-01]\n",
      " [4.24106198e-01 5.75893802e-01]\n",
      " [1.79812397e-01 8.20187603e-01]\n",
      " [9.77589945e-01 2.24100548e-02]\n",
      " [1.52338756e-02 9.84766124e-01]\n",
      " [5.51183368e-02 9.44881663e-01]\n",
      " [9.95944566e-01 4.05543428e-03]\n",
      " [9.99640360e-01 3.59639683e-04]\n",
      " [8.62012968e-01 1.37987032e-01]\n",
      " [9.80211549e-01 1.97884510e-02]\n",
      " [9.85221657e-01 1.47783426e-02]\n",
      " [9.82602569e-01 1.73974312e-02]\n",
      " [7.84949776e-01 2.15050224e-01]\n",
      " [9.94936482e-01 5.06351775e-03]\n",
      " [9.94425961e-01 5.57403918e-03]\n",
      " [9.42497977e-01 5.75020234e-02]\n",
      " [9.95456984e-01 4.54301570e-03]\n",
      " [1.60166478e-01 8.39833522e-01]\n",
      " [6.90640319e-01 3.09359681e-01]\n",
      " [8.53294748e-01 1.46705252e-01]\n",
      " [9.94528943e-01 5.47105679e-03]\n",
      " [9.47662491e-01 5.23375091e-02]\n",
      " [9.98908116e-01 1.09188385e-03]\n",
      " [9.98430742e-01 1.56925751e-03]\n",
      " [1.98386545e-01 8.01613455e-01]\n",
      " [9.84729277e-01 1.52707226e-02]\n",
      " [9.99595200e-01 4.04800069e-04]\n",
      " [9.99794957e-01 2.05042761e-04]\n",
      " [9.73692379e-01 2.63076209e-02]\n",
      " [9.96992293e-01 3.00770655e-03]\n",
      " [9.88949050e-01 1.10509500e-02]\n",
      " [1.28780255e-01 8.71219745e-01]\n",
      " [6.25002362e-01 3.74997638e-01]\n",
      " [4.76080959e-02 9.52391904e-01]\n",
      " [9.53729299e-01 4.62707011e-02]\n",
      " [7.81726677e-02 9.21827332e-01]\n",
      " [9.99024014e-01 9.75985582e-04]\n",
      " [8.08551465e-01 1.91448535e-01]\n",
      " [1.46561085e-01 8.53438915e-01]\n",
      " [5.85704586e-03 9.94142954e-01]\n",
      " [9.94590998e-01 5.40900230e-03]\n",
      " [4.72645158e-01 5.27354842e-01]\n",
      " [9.99861752e-01 1.38248472e-04]\n",
      " [1.21491970e-01 8.78508030e-01]\n",
      " [9.81877332e-01 1.81226677e-02]\n",
      " [9.68902457e-01 3.10975430e-02]\n",
      " [7.90122942e-01 2.09877058e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "clf_prob = LinearSVC(penalty='l1',dual=False,C=min_C)\n",
    "calibrated_svc = CalibratedClassifierCV(clf_prob,method='sigmoid') # probabilities estimated via sigmoid method\n",
    "calibrated_svc.fit(X_train,y_train)\n",
    "y_train_pred_prob = calibrated_svc.predict_proba(X_train)\n",
    "\n",
    "print(y_train_pred_prob)\n",
    "\n",
    "# References for this code https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html#sphx-glr-auto-examples-calibration-plot-calibration-curve-py\n",
    "# References for this code https://stackoverflow.com/questions/35212213/sklearn-how-to-get-decision-probabilities-for-linearsvc-classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column 1 : Probability of classifying to 0\n",
    "Column 2 : Probability of classifying to 1\n",
    "\n",
    "These probabilities will be used for the ROC curves and for AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.19475125e-03 9.96826196e-01 7.80424122e-03 9.89412847e-01\n",
      " 8.43557597e-02 8.46308841e-01 3.69495632e-02 8.81198933e-01\n",
      " 9.99851943e-01 9.14301381e-01 9.31603811e-01 7.82525170e-02\n",
      " 9.57557807e-01 2.56678517e-03 9.97595407e-01 1.42115858e-01\n",
      " 4.13021243e-01 9.92222555e-01 9.96431491e-01 9.99442051e-01\n",
      " 4.38086757e-02 9.87022455e-01 9.99972218e-01 8.15784125e-01\n",
      " 9.99319710e-01 1.28885698e-03 6.59915994e-02 6.73612584e-01\n",
      " 1.06811521e-01 9.19346122e-01 4.18182684e-02 9.77028241e-01\n",
      " 3.23063968e-01 9.98831744e-01 9.94833794e-01 2.06578884e-02\n",
      " 7.84407789e-01 9.58108140e-01 7.60074122e-02 1.75842318e-01\n",
      " 6.75073575e-01 7.84595233e-01 9.76316974e-01 7.31078201e-01\n",
      " 2.56082590e-03 2.99786402e-02 9.80299001e-01 9.43289139e-02\n",
      " 8.89823752e-01 7.17023028e-02 9.99872598e-01 9.88187117e-01\n",
      " 8.58042014e-01 5.45141001e-03 9.93554548e-01 6.37051314e-02\n",
      " 1.69022441e-01 9.98770964e-01 9.98441665e-01 3.50993454e-02\n",
      " 8.20711988e-01 9.84940339e-01 5.33998359e-01 5.15147922e-01\n",
      " 9.40950299e-01 1.09712667e-01 4.98811846e-03 9.54240360e-01\n",
      " 9.30714569e-01 6.58853115e-02 9.81525775e-01 6.25254048e-01\n",
      " 2.38500253e-02 9.48894858e-04 9.90963239e-01 3.83416754e-02\n",
      " 2.07700527e-02 9.51458903e-01 2.06084738e-01 9.97061992e-01\n",
      " 3.87886294e-01 8.67275578e-01 9.77128545e-01 9.53994485e-01\n",
      " 8.66179335e-01 9.76361370e-01 9.99927815e-01 2.94258752e-01\n",
      " 1.50321508e-01 8.45795263e-01 6.12685989e-02 9.76660699e-01\n",
      " 1.45532568e-02 1.97444262e-01 1.81195265e-03 9.28195459e-01\n",
      " 3.36291026e-01 9.61131074e-01 5.39139177e-03 5.44100080e-02\n",
      " 7.48629331e-02 7.78979519e-01 9.17651985e-01 8.92125342e-01\n",
      " 1.22943243e-02 9.88981121e-01 9.80612749e-01 9.84358335e-01\n",
      " 1.10718194e-03 1.76334356e-02 9.95727587e-01 9.99991510e-01\n",
      " 9.70188304e-01 9.97389220e-01 9.92327108e-01 9.90605038e-01\n",
      " 9.98199961e-01 1.22856282e-02 9.86228398e-01 8.58309059e-01\n",
      " 9.22627516e-01 9.99905376e-01 9.70018984e-01 9.53423520e-01\n",
      " 9.96117085e-01 6.54611267e-02 9.76326902e-01 2.63218450e-01\n",
      " 8.42445033e-01 9.99465946e-01 9.95972474e-01 9.39574120e-01\n",
      " 9.43208639e-01 9.07199375e-01 5.17087590e-02 5.37191286e-03\n",
      " 9.97351977e-01 9.71550409e-01 1.21336096e-02 9.95435800e-01\n",
      " 4.44732448e-02 9.97208608e-01 3.27420856e-03 9.94290597e-01\n",
      " 2.60520829e-02 8.90662776e-01 9.13072566e-01 8.63171741e-01\n",
      " 9.66517992e-01 2.67143559e-02 7.77182370e-01 6.01359023e-01\n",
      " 9.52496159e-01 9.99463089e-01 8.43577961e-01 6.58654836e-01\n",
      " 9.14340704e-01 9.68410799e-01 9.93503940e-01 9.40352316e-01\n",
      " 9.99825231e-01 2.34251370e-01 5.46311978e-01 5.46472141e-02\n",
      " 9.98408902e-01 5.74127149e-01 5.68209572e-01 9.31407341e-03\n",
      " 9.87636307e-01 1.41887497e-02 6.76577426e-03 4.33815896e-02\n",
      " 9.82992138e-01 9.70030821e-01 3.36902821e-01 2.33417341e-04\n",
      " 8.80857412e-01 9.91422996e-01 9.81760678e-01 2.58236742e-02\n",
      " 1.90676877e-02 9.99158977e-01 2.33141614e-01 9.53941300e-01\n",
      " 3.06354555e-02 5.79516277e-02 9.96472830e-01 9.89126526e-01\n",
      " 6.55864074e-01 9.82991534e-01 9.53626630e-01 1.55404179e-01\n",
      " 8.49737510e-02 9.71936129e-01 8.96791201e-01 9.93895812e-01\n",
      " 3.19163614e-02 6.52853250e-01 1.76945142e-01 7.69182972e-03\n",
      " 6.58548647e-02 8.44668175e-01 3.51940408e-03 9.61695001e-01\n",
      " 1.18167065e-03 1.82410437e-05 9.68609527e-01 6.09079491e-02\n",
      " 7.55713023e-01 9.04512791e-01 9.91027833e-01 3.60024016e-02\n",
      " 9.95303599e-01 9.88616803e-01 4.84600418e-01 1.40256139e-01\n",
      " 1.19648815e-01 1.22901546e-02 9.81293745e-01 9.98867938e-01\n",
      " 9.89138900e-01 9.88760092e-01 9.98551237e-01 1.79599414e-03\n",
      " 9.99996826e-01 2.53693478e-02 9.23516927e-01 5.87434578e-02\n",
      " 9.92682186e-01 9.33950430e-02 9.99456287e-01 3.26842286e-02\n",
      " 7.89242576e-01 9.98025597e-01 1.29111292e-02 9.97174524e-01\n",
      " 9.33777463e-01 8.92184428e-01 7.04302773e-01 2.57038647e-01\n",
      " 9.77498403e-01 9.95672838e-01 9.16874979e-03 9.96070457e-01\n",
      " 4.18851513e-01 8.44889238e-03 1.12579606e-01 9.77914601e-01\n",
      " 1.11069860e-02 9.65967217e-01 9.50431834e-01 2.11229240e-02\n",
      " 2.43252370e-02 4.51009471e-01 7.08214516e-02 9.25702798e-01\n",
      " 9.99973481e-01 1.68266140e-01 3.54651762e-03 3.56530519e-03\n",
      " 6.30362793e-01 9.99585844e-01 9.99934481e-01 5.25307706e-01\n",
      " 8.02584550e-01 9.99240872e-01 9.94679682e-01 1.87934967e-02\n",
      " 2.27501009e-02 3.98950566e-04 9.99864420e-01 9.70634179e-01\n",
      " 8.75223591e-01 9.67828605e-01 8.69067497e-01 3.59701825e-03\n",
      " 9.38547841e-01 9.18871250e-01 4.79068295e-02 5.50260505e-02\n",
      " 9.81517605e-03 6.68556324e-01 8.35906365e-01 4.44264697e-01\n",
      " 5.71347668e-01 9.95522997e-01 3.31510963e-03 1.06962519e-02\n",
      " 9.99976026e-01 9.26903813e-01 6.05732591e-01 9.42707076e-01\n",
      " 2.75842266e-02 5.79904633e-02 7.63286042e-01 9.69414059e-01\n",
      " 9.99667265e-01 9.98755744e-01 9.00306440e-01 9.85690110e-01\n",
      " 2.06552613e-02 2.99403281e-02 9.83434376e-01 9.91648786e-01\n",
      " 9.98267233e-01 7.73470620e-01 9.99998293e-01 6.67597591e-03\n",
      " 9.96341594e-01 9.97021968e-01 7.78311263e-01 9.80934187e-01\n",
      " 9.70988327e-01 3.46756310e-02 9.58936410e-01 1.37051768e-02\n",
      " 7.93500404e-05 8.00187774e-01 3.74650212e-01 9.74178722e-01\n",
      " 9.99926294e-01 9.89468859e-01 7.12491903e-02 9.94035415e-01\n",
      " 1.68666903e-01 9.99271455e-01 9.85117509e-01 8.40385585e-01\n",
      " 8.95423974e-01 9.22379251e-01 9.34160675e-01 5.47444156e-02\n",
      " 9.75366063e-01 9.86031087e-01 9.55725136e-01 9.17157411e-01\n",
      " 9.85534131e-01 7.88375121e-01 9.96695950e-01 9.73279643e-01\n",
      " 3.63050346e-02 9.66439378e-01 9.43632242e-01 9.99567437e-01\n",
      " 6.89530655e-01 7.35089107e-01 2.76170324e-02 9.79226243e-01\n",
      " 3.80597261e-01 9.97290525e-01 9.99517847e-01 9.92566762e-01\n",
      " 9.44706299e-01 9.97264939e-01 9.88719452e-01 5.14900250e-01\n",
      " 9.50909268e-01 7.61402329e-01 9.76933815e-01 9.91040394e-01\n",
      " 6.92813666e-01 9.54689937e-01 9.94965849e-01 9.96683186e-01\n",
      " 8.51534602e-01 9.32119160e-03 3.63696418e-04 9.64836248e-03\n",
      " 1.13323285e-03 1.87586687e-02 9.69445042e-01 9.99873641e-01\n",
      " 9.10671476e-01 8.77020742e-01 7.85779369e-01 9.97325977e-01\n",
      " 9.99570917e-01 1.90254158e-01 9.77583603e-01 9.60131953e-01\n",
      " 9.90248783e-01 9.98378751e-01 8.31192708e-01 9.99455610e-01\n",
      " 1.89949907e-01 9.93720118e-01 9.78075214e-01 3.44467804e-02\n",
      " 2.80243993e-02 5.94255470e-02 6.58210112e-01 9.99918025e-01\n",
      " 9.98425466e-01 9.06029371e-01 6.22435829e-01 1.78669410e-02\n",
      " 2.26963194e-02 3.59878324e-03 9.98387375e-01 9.62623282e-01\n",
      " 1.35695663e-02 2.68685106e-02 3.61372976e-02 2.59162082e-01\n",
      " 9.24163071e-01 7.52099414e-01 9.80569258e-01 4.67588361e-03\n",
      " 4.24106198e-01 1.79812397e-01 9.77589945e-01 1.52338756e-02\n",
      " 5.51183368e-02 9.95944566e-01 9.99640360e-01 8.62012968e-01\n",
      " 9.80211549e-01 9.85221657e-01 9.82602569e-01 7.84949776e-01\n",
      " 9.94936482e-01 9.94425961e-01 9.42497977e-01 9.95456984e-01\n",
      " 1.60166478e-01 6.90640319e-01 8.53294748e-01 9.94528943e-01\n",
      " 9.47662491e-01 9.98908116e-01 9.98430742e-01 1.98386545e-01\n",
      " 9.84729277e-01 9.99595200e-01 9.99794957e-01 9.73692379e-01\n",
      " 9.96992293e-01 9.88949050e-01 1.28780255e-01 6.25002362e-01\n",
      " 4.76080959e-02 9.53729299e-01 7.81726677e-02 9.99024014e-01\n",
      " 8.08551465e-01 1.46561085e-01 5.85704586e-03 9.94590998e-01\n",
      " 4.72645158e-01 9.99861752e-01 1.21491970e-01 9.81877332e-01\n",
      " 9.68902457e-01 7.90122942e-01]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_prob_0 = y_train_pred_prob[:,0]\n",
    "print(y_train_pred_prob_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           FPR       TPR\n",
      "0.00         0         0\n",
      "0.01         0  0.224852\n",
      "0.02         0  0.325444\n",
      "0.03         0  0.431953\n",
      "0.04         0  0.497041\n",
      "...        ...       ...\n",
      "0.96  0.396491         1\n",
      "0.97  0.442105         1\n",
      "0.98  0.526316         1\n",
      "0.99  0.645614         1\n",
      "1.00         1         1\n",
      "\n",
      "[101 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "thresh = np.arange(0,1.01,0.01)\n",
    "ROC_df = pd.DataFrame(index=thresh,columns=['FPR','TPR'])\n",
    "for i in np.arange(0,thresh.size):\n",
    "    y_train_pred_roc = (y_train_pred_prob_0 <= thresh[i]).astype(int)\n",
    "    confusion_matrix_train_roc = confusion_matrix(y_train,y_train_pred_roc)\n",
    "    ROC_df.iloc[i,0] = confusion_matrix_train_roc[0][1]/(confusion_matrix_train_roc[0][1]+confusion_matrix_train_roc[0][0])\n",
    "    ROC_df.iloc[i,1] = confusion_matrix_train_roc[1][1]/(confusion_matrix_train_roc[1][1]+confusion_matrix_train_roc[1][0])\n",
    "print(ROC_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'TPR for Train')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAVFUlEQVR4nO3de5CldX3n8feHGe53nGFhYWBGAcNIBLQD2cpqSKEUUBaTbBEXahFUlFp30U1wU0sqG3RxK/GyxiojuzgqqyEVUUmMve4YTBQvq2JoMkiYEeI43DqwMiggdxj47h/njHvs6T59erqfc9L9vF9Vp/q5/M5zvr/pnv70c/s9qSokSe2126gLkCSNlkEgSS1nEEhSyxkEktRyBoEktdzyURcwVytWrKjVq1ePugxJWlRuueWWh6pq5XTrFl0QrF69momJiVGXIUmLSpJ7ZlrnoSFJajmDQJJaziCQpJYzCCSp5QwCSWq5xoIgyTVJHkxy+wzrk+TDSbYkuS3JK5qqRZI0syb3CD4JnNln/VnAsd3XJcD/aLAWSdIMGruPoKq+kWR1nybrgD+pzjjYNyU5KMnhVfVAUzWN2oOPPc3Gex/hjgce4/kXXhh1OZIWmdOP/2ecuOqgBd/uKG8oOwK4r2d+srtspyBIcgmdvQaOOuqooRS3w8NPPMu3f/hjil17bsOPfvoMG+99mI33PsI/PvLUz5YnC1WhpLY49IC9llwQTPercNrftlW1HlgPMDY2NpQn6Tz+zHbufugJ3nHdRrZue2Je2zrioL05+aiDePO/XMPJRx3E2sMPYK/dly1QpZI0P6MMgklgVc/8kcD9I6oFgO3Pv8A3f/AQf/53k/z15h/xzPYX2HP5bnzswjFWv2ifXdrmgfvszqH777XAlUrSwhllEIwDlya5DjgVeHQU5weee/4Frrv5Pv74Kz/gwceeAeDgfXbnX//SKn5p9SEcf/j+HHPo/sMuS5KGprEgSPJp4DRgRZJJ4F3A7gBVdTWwATgb2AI8CbypqVpmcv8jT3HhNX/Llgcf55TVh3DeKUdxwj8/gNNeeih7LPcWC0nt0ORVQ+fPsr6Af9/U589k22PP8L6/uoOnn3ue700+wiNPPsfHLhzjNccfSjyDK6mFFt0w1PN1yz0/4fpbJjnioL05aJ/d+eBvnsQpaw4ZdVmSNDKtC4IdPn7RGMcffsCoy5CkkfNAuCS1nEEgSS3XuiCYfLhzd+9unhiWJKBlQXD7Pz7Ke790B6euOYRjDt1v1OVI0j8JrQmCH257nHePb2L7C8X7z305y3Zzj0CSoEVB8Debf8TEPQ/zyqMP5rADHfJBknZoTRDscO3Fp7Dncgd8k6QdWhcEkqSfZxBIUssZBJLUcgaBJLWcQSBJLWcQSFLLGQSS1HIGgSS1nEEgSS1nEEhSyxkEktRyBoEktZxBIEktZxBIUssZBJLUcgaBJLWcQSBJLWcQSFLLGQSS1HIGgSS1nEEgSS1nEEhSyzUaBEnOTHJnki1JLp9m/VFJbkyyMcltSc5ush5J0s4aC4Iky4CrgLOAtcD5SdZOafafgc9W1cnAecB/b6oeSdL0mtwjOAXYUlVbq+pZ4Dpg3ZQ2BRzQnT4QuL/BeiRJ02gyCI4A7uuZn+wu6/Vu4IIkk8AG4O3TbSjJJUkmkkxs27atiVolqbWaDIJMs6ymzJ8PfLKqjgTOBq5NslNNVbW+qsaqamzlypUNlCpJ7dVkEEwCq3rmj2TnQz8XA58FqKrvAHsBKxqsSZI0RZNBcDNwbJI1SfagczJ4fEqbe4HTAZIcTycIPPYjSUPUWBBU1XbgUuAG4Pt0rg7alOTKJOd0m70TeGuS7wGfBt5YVVMPH0mSGrS8yY1X1QY6J4F7l13RM70Z+JUma5Ak9eedxZLUcgaBJLWcQSBJLWcQSFLLGQSS1HIGgSS1nEEgSS1nEEhSyxkEktRyBoEktZxBIEktZxBIUssZBJLUcgaBJLWcQSBJLWcQSFLLGQSS1HIGgSS1nEEgSS1nEEhSyxkEktRyBoEktZxBIEktt3y2Bkn2AH4dWN3bvqr+oLmyJEnDMmsQAJ8HngZuAZ5vthxJ0rANEgRHV9UJjVciSRqJQc4R3JRkbeOVSJJGYpA9glOBjUm2AM8AAaqqXtFoZZKkoRgkCH698SokSSMzYxAk2beqngC2DbEeSdKQ9TtHcH336ybg9u7XTT3zs0pyZpI7k2xJcvkMbV6fZHOSTUn+bA61S5IWwIx7BFV1Vvfrql3ZcJJlwFXAa4FJ4OYk41W1uafNscDvAr9SVQ8nOXRXPkuStOsGOUdAkgOBlwB77VhWVd+e5W2nAFuqamt3G9cB64DNPW3eClxVVQ93t/ng4KVLkhbCrJePJrkY+DbwVeB93a+D3FV8BHBfz/xkd1mv44DjknwryU1JzpyhhkuSTCSZ2LbNUxaStJAGuY/gt4Ax4O6qehXwSuCBAd6XaZbVlPnlwLHAacD5wMeTHLTTm6rWV9VYVY2tXLlygI+WJA1qkCB4uqqegs64Q1W1CfiFAd43CfSeXzgSuH+aNl+oqueq6i7gTjrBIEkakkGC4IHuX+n/C7ghyZ8DPxrgfTcDxyZZ0x247jxgfEqbvwR+DSDJCjqHirYOWrwkaf5mPVlcVed0J38/yenAgcD/HuB925NcCtwALAOuqapNSa4EJqpqvLvujCSb6Qxo9ztV9eNd7IskaRf0DYLuJaB/V1UnAlTVV+ay8araAGyYsuyKnukCLuu+JEkj0PfQUFU9D2xOMvVqH0nSEjHIfQQrgO8n+Q7wxI6FVfWvGqtKkjQ0gwTBexuvQpI0Mv0GnftyVZ0x1/MCkqTFpd85Au/ckqQW6Hdo6MAkM54HqKq/aKAeSdKQ9Q0C4HXMPFSEQSBJS0C/ILinqt48tEokSSPR7xzBdHsCkqQlpl8QvGFoVUiSRmbGIKiqgR5HKUla3AYZfVSStIT1DYIky5L86bCKkSQN3yCDzq3sPk9AkrQEDTLW0N3At5KM8/ODzv1RU0VJkoZnkCC4v/vaDdi/2XIkScM2yBPK/gtAkv07s/V441VJkoZm1quGkpyQZCNwO7ApyS1JXtZ8aZKkYRjk8tH1wGVVdXRVHQ28E/hYs2VJkoZlkCDYt6pu3DFTVV8D9m2sIknSUA1ysnhrkt8Hru3OXwDc1VxJkqRhGmSP4M10HlLzF93XCuBNTRYlSRqefo+qvLaq3gBcWFXvGGJNkqQh6rdH8MokRwNvTnJwkkN6X8MqUJLUrH7nCK4G/gp4MXALP/98guoulyQtcv2Gof5wVR0PXFNVL66qNT0vQ0CSlohZTxZX1duGUYgkaTR8HoEktZxBIEktN+cg6D6s5t80UYwkafhmDIIkByT53SQfSXJGOt4ObAVeP7wSJUlN6rdHcC3wUuDvgbcAXwbOBdZV1bpBNp7kzCR3JtmS5PI+7c5NUknG5lC7JGkB9LuP4MVV9YsAST4OPAQcVVWPDbLhJMuAq4DXApPAzUnGq2rzlHb7A+8AvrsL9UuS5qnfHsFzOya6zy6+a9AQ6DoF2FJVW6vqWeA6YLo9ifcA7weensO2JUkLpF8QnJjkp0keS/IY8PKe+Z8OsO0jgPt65ie7y34mycnAqqr6Yr8NJbkkyUSSiW3btg3w0ZKkQc14aKiqls1z25lmWf1sZbIb8CHgjbNtqKrW03lADmNjYzVLc0nSHPQbfXQv4N8CxwC30RlqYvsctj0JrOqZPxK4v2d+f+AE4GtJAA4DxpOcU1UTc/gcSdI89Ds09ClgjM5VQ2cDH5zjtm8Gjk2yJskewHnA+I6VVfVoVa2oqtVVtRq4CTAEJGnI+l01tLbnqqFPAH87lw1X1fYklwI3AMvo7FFsSnIlMFFV4/23IEkahn5B0HvV0Pbu4Zs5qaoNwIYpy66Yoe1pc/4ASdK89QuCk3quDgqwd3c+QFXVAY1XJ0lqXL8g+F5VnTy0SiRJI9HvZLGXaUpSC/TbIzg0yWUzrayqP2qgHknSkPULgmXAfkx/Y5gkaYnoFwQPVNWVQ6tEkjQS/c4RuCcgSS3QLwhOH1oVkqSRmTEIquonwyxEkjQaPrxeklrOIJCkljMIJKnlDAJJajmDQJJaziCQpJYzCCSp5QwCSWo5g0CSWs4gkKSWMwgkqeUMAklqOYNAklrOIJCkljMIJKnlDAJJajmDQJJaziCQpJYzCCSp5QwCSWo5g0CSWq7RIEhyZpI7k2xJcvk06y9LsjnJbUm+kuToJuuRJO2ssSBIsgy4CjgLWAucn2TtlGYbgbGqejlwPfD+puqRJE2vyT2CU4AtVbW1qp4FrgPW9Taoqhur6snu7E3AkQ3WI0maRpNBcARwX8/8ZHfZTC4GvjTdiiSXJJlIMrFt27YFLFGS1GQQZJplNW3D5AJgDPjAdOuran1VjVXV2MqVKxewREnS8ga3PQms6pk/Erh/aqMkrwF+D/jVqnqmwXokSdNoco/gZuDYJGuS7AGcB4z3NkhyMvBR4JyqerDBWiRJM2gsCKpqO3ApcAPwfeCzVbUpyZVJzuk2+wCwH/C5JLcmGZ9hc5KkhjR5aIiq2gBsmLLsip7p1zT5+ZKk2XlnsSS1nEEgSS1nEEhSyxkEktRyBoEktZxBIEktZxBIUssZBJLUcgaBJLWcQSBJLWcQSFLLGQSS1HIGgSS1nEEgSS1nEEhSyxkEktRyBoEktZxBIEktZxBIUssZBJLUcgaBJLWcQSBJLWcQSFLLGQSS1HIGgSS1nEEgSS1nEEhSyxkEktRyBoEktZxBIEktZxBIUss1GgRJzkxyZ5ItSS6fZv2eST7TXf/dJKubrEeStLPGgiDJMuAq4CxgLXB+krVTml0MPFxVxwAfAt7XVD2SpOk1uUdwCrClqrZW1bPAdcC6KW3WAZ/qTl8PnJ4kDdYkSZqiySA4ArivZ36yu2zaNlW1HXgUeNHUDSW5JMlEkolt27btUjFrVuzL2b94GLuZM5L0c5Y3uO3pfuPWLrShqtYD6wHGxsZ2Wj+IM152GGe87LBdeaskLWlN7hFMAqt65o8E7p+pTZLlwIHATxqsSZI0RZNBcDNwbJI1SfYAzgPGp7QZBy7qTp8LfLWqdukvfknSrmns0FBVbU9yKXADsAy4pqo2JbkSmKiqceATwLVJttDZEzivqXokSdNr8hwBVbUB2DBl2RU9008Dv9lkDZKk/ryzWJJaziCQpJYzCCSp5QwCSWq5LLarNZNsA+7ZxbevAB5awHIWA/vcDva5HebT56OrauV0KxZdEMxHkomqGht1HcNkn9vBPrdDU3320JAktZxBIEkt17YgWD/qAkbAPreDfW6HRvrcqnMEkqSdtW2PQJI0hUEgSS23JIMgyZlJ7kyyJcnl06zfM8lnuuu/m2T18KtcWAP0+bIkm5PcluQrSY4eRZ0LabY+97Q7N0klWfSXGg7S5ySv736vNyX5s2HXuNAG+Nk+KsmNSTZ2f77PHkWdCyXJNUkeTHL7DOuT5MPdf4/bkrxi3h9aVUvqRWfI6x8CLwb2AL4HrJ3S5t8BV3enzwM+M+q6h9DnXwP26U6/rQ197rbbH/gGcBMwNuq6h/B9PhbYCBzcnT901HUPoc/rgbd1p9cCd4+67nn2+dXAK4DbZ1h/NvAlOk94/GXgu/P9zKW4R3AKsKWqtlbVs8B1wLopbdYBn+pOXw+cnizqhxnP2uequrGqnuzO3kTniXGL2SDfZ4D3AO8Hnh5mcQ0ZpM9vBa6qqocBqurBIde40AbpcwEHdKcPZOcnIS4qVfUN+j+pcR3wJ9VxE3BQksPn85lLMQiOAO7rmZ/sLpu2TVVtBx4FXjSU6poxSJ97XUznL4rFbNY+JzkZWFVVXxxmYQ0a5Pt8HHBckm8luSnJmUOrrhmD9PndwAVJJuk8/+TtwyltZOb6/31WjT6YZkSm+8t+6jWyg7RZTAbuT5ILgDHgVxutqHl9+5xkN+BDwBuHVdAQDPJ9Xk7n8NBpdPb6vpnkhKp6pOHamjJIn88HPllVH0zyL+g89fCEqnqh+fJGYsF/fy3FPYJJYFXP/JHsvKv4szZJltPZney3K/ZP3SB9JslrgN8DzqmqZ4ZUW1Nm6/P+wAnA15LcTedY6vgiP2E86M/2F6rquaq6C7iTTjAsVoP0+WLgswBV9R1gLzqDsy1VA/1/n4ulGAQ3A8cmWZNkDzong8entBkHLupOnwt8tbpnYRapWfvcPUzyUTohsNiPG8Msfa6qR6tqRVWtrqrVdM6LnFNVE6Mpd0EM8rP9l3QuDCDJCjqHirYOtcqFNUif7wVOB0hyPJ0g2DbUKodrHLiwe/XQLwOPVtUD89ngkjs0VFXbk1wK3EDnioNrqmpTkiuBiaoaBz5BZ/dxC509gfNGV/H8DdjnDwD7AZ/rnhe/t6rOGVnR8zRgn5eUAft8A3BGks3A88DvVNWPR1f1/AzY53cCH0vy23QOkbxxMf9hl+TTdA7treie93gXsDtAVV1N5zzI2cAW4EngTfP+zEX87yVJWgBL8dCQJGkODAJJajmDQJJaziCQpJYzCCSp5QwCLSlJnk9ya89rdZLTkjzaHZ3y+0ne1W3bu/yOJP+tz3Y/3R3p8bd3oaY39dTzbJK/706/dw7bWJXkM3P9bGkQXj6qJSXJ41W135RlpwH/sapel2Rf4FY6947s37N8bzqjdl5cVd+a8v7D6IzwOPDQ3UmWd8exmrr8bjqjoD406HukprlHoFapqieAW4CXTFn+FJ2AmG7wri8Dh3b/in9VkpO6A7rdluTzSQ4GSPK1JH+Q5OvAfxikniT/NclHk/w18D+TvCTJN7t7KbckObXb7pgkt3an35Lk+iQ3JPlBkj/c1X8PCZbgncVqvb13/MIE7qqq3+hdmeRFdMYdeg+wsmf5wXTG5PnGNNs8B/hiVZ3UbXsb8Paq+nr3Dtd3Ab/VbXtQVc11QL+TgVdX1dNJ9gFe253+BTrDpZ86zXtOpDNm/XbgH5L8cVUt6uGXNToGgZaap3b8wp7iVUk2Ai8A7+0OU3Bad/ltwEu7y/9vv40nOZDOL/uvdxd9CvhcT5NdOY7/hara8byEPYGPJDmRzi/5l8zwnr+pqse6Nd0BHMUiH4dfo2MQqC2+WVWvm2l5kuOA/5Pk81V16zTtBvXEPN/zTjpjzV9AZ3yZx2d4T+/osc/j/2XNg+cIJKCq/gH4Q+A/zdLuUeDhJK/qLnoD8PU+b5mrA4EHuoOmXcT0Y89LC8ogkP6/q4FXJ1kzS7uLgA90DymdBFy5gDV8BHhLkpuAo/n5v/ylRnj5qCS1nHsEktRyBoEktZxBIEktZxBIUssZBJLUcgaBJLWcQSBJLff/APJMA3ygM0m7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(ROC_df['FPR'],ROC_df['TPR'])\n",
    "plt.xlabel('FPR for Train')\n",
    "plt.ylabel('TPR for Train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC for Train, as seen above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for train is : \n",
      " 0.9984947576040694\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "AUC_train = metrics.auc(ROC_df['FPR'],ROC_df['TPR'])\n",
    "print('The AUC for train is : \\n',AUC_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.87914112e-01 2.95722008e-02 5.40660964e-02 1.82514763e-01\n",
      " 6.77556212e-01 5.30794873e-01 9.99999297e-01 9.99932542e-01\n",
      " 3.06842063e-02 7.23908449e-01 9.57465035e-01 9.60202803e-03\n",
      " 9.90411941e-01 1.67174952e-03 9.99999893e-01 9.99395496e-01\n",
      " 9.74482553e-01 1.00281658e-02 9.78412960e-01 6.31515358e-03\n",
      " 9.99069495e-01 5.11584790e-02 9.69048363e-01 4.52281024e-02\n",
      " 6.81397309e-03 9.74661710e-01 8.57151161e-01 7.87259470e-01\n",
      " 1.05601688e-01 9.89489815e-01 4.74812300e-01 1.77456860e-02\n",
      " 9.27428554e-01 1.93651137e-02 5.02643641e-01 2.56514912e-01\n",
      " 9.88497588e-01 3.74933119e-03 1.23594285e-01 9.99052251e-01\n",
      " 7.15733448e-01 9.97020266e-01 9.96167658e-01 5.87513758e-02\n",
      " 8.94047288e-01 9.95332539e-01 3.55057533e-01 2.73701837e-03\n",
      " 2.39462829e-03 6.24080726e-03 9.79086993e-01 9.61694387e-01\n",
      " 1.88943831e-02 8.90994004e-01 9.19716752e-01 9.36639993e-01\n",
      " 4.97225919e-01 9.99186867e-01 9.59179684e-01 9.77644740e-01\n",
      " 9.51978880e-01 6.82927727e-01 8.52111668e-01 2.04232921e-03\n",
      " 9.93555941e-01 9.95613184e-01 1.13254280e-02 8.43213095e-01\n",
      " 9.99074131e-01 9.50887859e-01 9.27654071e-01 5.75057466e-03\n",
      " 8.86266900e-01 3.18636276e-02 7.14268811e-03 9.94951951e-01\n",
      " 5.90892467e-02 9.96387541e-01 3.55871179e-03 9.63841072e-01\n",
      " 6.56690205e-01 4.63192942e-02 8.54016942e-02 4.75709650e-01\n",
      " 3.37655798e-02 1.35591197e-01 2.47000497e-02 9.75645212e-01\n",
      " 6.43281415e-04 5.67826126e-03 9.99600128e-01 9.98928696e-01\n",
      " 9.66844831e-01 9.88113349e-01 9.96277162e-01 3.16267987e-01\n",
      " 5.57204361e-01 9.83569639e-01 9.70844363e-01 6.91282907e-01\n",
      " 7.79865344e-02 9.71340420e-01 8.01614380e-01 7.98567908e-01\n",
      " 9.69042169e-01 9.80090171e-01 9.98689818e-01 9.95828181e-01\n",
      " 2.08175526e-03 9.43121375e-04 9.82634751e-01 9.87583569e-01\n",
      " 7.04075366e-01 9.72057391e-01 9.98800701e-01]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_prob = calibrated_svc.predict_proba(X_test)\n",
    "y_test_pred_prob_0 = y_test_pred_prob[:,0]\n",
    "print(y_test_pred_prob_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           FPR       TPR\n",
      "0.00         0         0\n",
      "0.01         0  0.372093\n",
      "0.02         0  0.488372\n",
      "0.03         0  0.534884\n",
      "0.04         0  0.604651\n",
      "...        ...       ...\n",
      "0.96  0.388889         1\n",
      "0.97  0.458333         1\n",
      "0.98  0.583333         1\n",
      "0.99  0.694444         1\n",
      "1.00         1         1\n",
      "\n",
      "[101 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "thresh = np.arange(0,1.01,0.01)\n",
    "ROC_df_test = pd.DataFrame(index=thresh,columns=['FPR','TPR'])\n",
    "for i in np.arange(0,thresh.size):\n",
    "    y_test_pred_roc = (y_test_pred_prob_0 <= thresh[i]).astype(int)\n",
    "    confusion_matrix_test_roc = confusion_matrix(y_test,y_test_pred_roc)\n",
    "    ROC_df_test.iloc[i,0] = confusion_matrix_test_roc[0][1]/(confusion_matrix_test_roc[0][1]+confusion_matrix_test_roc[0][0])\n",
    "    ROC_df_test.iloc[i,1] = confusion_matrix_test_roc[1][1]/(confusion_matrix_test_roc[1][1]+confusion_matrix_test_roc[1][0])\n",
    "print(ROC_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'TPR for Test')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ROC_df_test['FPR'],ROC_df_test['TPR'])\n",
    "plt.xlabel('FPR for Test')\n",
    "plt.ylabel('TPR for Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for test is : \n",
      " 0.9956395348837209\n"
     ]
    }
   ],
   "source": [
    "AUC_test = metrics.auc(ROC_df_test['FPR'],ROC_df_test['TPR'])\n",
    "print('The AUC for test is : \\n',AUC_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above are ROC curves for test and AUC for test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these values and curves have been shown for one Random Monte-Carlo iteration\n",
    "\n",
    "So for the actual M=30 Monte-Carlo iterations, we will not show the curves and confusion matrices for train and test for a random Monte-Carlo trial, as they have already been shown here for some random Monte-Carlo trial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
