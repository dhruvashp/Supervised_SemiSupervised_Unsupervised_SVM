{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passive Learning Test\n",
    "(M=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          X1        X2       X3       X4  y\n",
      "0    1.35660   4.23580  2.13410  0.32110  0\n",
      "1    0.51950  -3.26330  3.08950 -0.98490  0\n",
      "2   -1.11930  10.72710  2.09380 -5.65040  0\n",
      "3    1.43780   0.66837 -2.02670  1.02710  1\n",
      "4   -2.01490   3.68740 -1.93850 -3.89180  1\n",
      "..       ...       ...      ...      ... ..\n",
      "895  1.25720   4.87310 -5.28610 -5.87410  1\n",
      "896 -0.82053   0.65181 -0.48869 -0.52716  1\n",
      "897 -1.66370   3.28810 -2.27010 -2.22240  1\n",
      "898  4.36340   0.46351  1.42810  2.02020  0\n",
      "899 -2.19790  -2.12520  1.71510  0.45171  1\n",
      "\n",
      "[900 rows x 5 columns]\n",
      "          X1        X2       X3       X4  y\n",
      "0   -7.03640  9.293100  0.16594 -4.53960  1\n",
      "1    0.53936  3.894400 -4.81660 -4.34180  1\n",
      "2   -0.49281  3.060500 -1.83560 -2.83400  1\n",
      "3   -0.83121  0.039307  0.05369 -0.23105  1\n",
      "4    1.67990  4.206800 -4.53980 -2.39310  1\n",
      "..       ...       ...      ...      ... ..\n",
      "467 -0.56877  1.417400 -1.42520 -1.12460  1\n",
      "468 -5.49010  9.104800 -0.38758 -5.97630  1\n",
      "469  0.85574  0.008268  6.60420 -0.53104  0\n",
      "470  3.48930  6.690000 -1.20420 -0.38751  0\n",
      "471  3.82130  0.231750  2.01330  2.05640  0\n",
      "\n",
      "[472 rows x 5 columns]\n",
      "          X1        X2       X3       X4\n",
      "0   -7.03640  9.293100  0.16594 -4.53960\n",
      "1    0.53936  3.894400 -4.81660 -4.34180\n",
      "2   -0.49281  3.060500 -1.83560 -2.83400\n",
      "3   -0.83121  0.039307  0.05369 -0.23105\n",
      "4    1.67990  4.206800 -4.53980 -2.39310\n",
      "..       ...       ...      ...      ...\n",
      "467 -0.56877  1.417400 -1.42520 -1.12460\n",
      "468 -5.49010  9.104800 -0.38758 -5.97630\n",
      "469  0.85574  0.008268  6.60420 -0.53104\n",
      "470  3.48930  6.690000 -1.20420 -0.38751\n",
      "471  3.82130  0.231750  2.01330  2.05640\n",
      "\n",
      "[472 rows x 4 columns]\n",
      "0      1\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "467    1\n",
      "468    1\n",
      "469    0\n",
      "470    0\n",
      "471    0\n",
      "Name: y, Length: 472, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "X_y_train = pd.read_csv('Bank_Train.csv',index_col=0)\n",
    "print(X_y_train)\n",
    "X_y_test = pd.read_csv('Bank_Test.csv',index_col=0)\n",
    "print(X_y_test)\n",
    "X_test = X_y_test.drop(columns=['y'])\n",
    "y_test = X_y_test['y']\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       10       20       30       40       50       60      70       80   \\\n",
      "1  11.0169  10.3814  2.75424  2.75424  2.75424  2.75424  2.9661  1.90678   \n",
      "\n",
      "       90       100  ...      810      820      830      840      850  \\\n",
      "1  2.11864  2.33051  ...  1.05932  1.05932  1.05932  1.05932  1.48305   \n",
      "\n",
      "       860      870      880      890      900  \n",
      "1  1.05932  1.05932  1.05932  1.05932  1.05932  \n",
      "\n",
      "[1 rows x 90 columns]\n"
     ]
    }
   ],
   "source": [
    "X_y_train_updated = X_y_train.copy()                  # to save the original X_y_train\n",
    "\n",
    "X_y_train_build = pd.DataFrame()                      # defining an empty dataframe where actual train samples will be stored\n",
    "\n",
    "C_range = np.array([10**(-3),10**(-2),10**(-1),10**(0),10**(1),10**(2),10**(3),10**(4),10**(5),10**(6)])\n",
    "\n",
    "Error_Test_df = pd.DataFrame(index=np.arange(1,2),columns=np.arange(10,910,10))\n",
    "\n",
    "# this range is typical, and is assumed. Range selection, as done previously, may be performed for penalty to obtain its upper\n",
    "# and lower limits, but since this range is usually typical, and since it has already been done once for a previous section, we\n",
    "# will assumed this C range rather than again seperately performing range selection here\n",
    "# As is, this is a sufficient enough range, as is the typical range the penalty usually lies in for SVM\n",
    "\n",
    "for i in np.arange(1,91):          # Directly\n",
    "    \n",
    "    if i != 90:\n",
    "        X_y_train_to_add, X_y_train_updated = train_test_split(X_y_train_updated,train_size=10,shuffle=True,stratify=X_y_train_updated['y'])\n",
    "        X_y_train_to_add.reset_index(drop=True,inplace=True)\n",
    "        X_y_train_updated.reset_index(drop=True,inplace=True)\n",
    "        \n",
    "    else:\n",
    "        X_y_train_to_add = X_y_train_updated\n",
    "    \n",
    "    \n",
    "    \n",
    "    X_y_train_build = pd.concat([X_y_train_build,X_y_train_to_add],axis=0)\n",
    "    \n",
    "    X_y_train_build.reset_index(drop=True,inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    CV_errors_df = pd.DataFrame(index=np.arange(0,5),columns=C_range) \n",
    "    \n",
    "    cv_ite = -1\n",
    "    \n",
    "    X_train_build = X_y_train_build.drop(columns=['y'])\n",
    "    y_train_build = X_y_train_build['y']\n",
    "    \n",
    "    \n",
    "    kf = KFold(n_splits=5,shuffle=True)        # Normal KFold\n",
    "                                               # As such if needed it is easy to perform stratified KFold as well\n",
    "    \n",
    "    for train,test in kf.split(X_train_build):\n",
    "        \n",
    "        cv_ite = cv_ite + 1\n",
    "        \n",
    "        X_train_cv, X_test_cv = X_train_build.iloc[train,:],X_train_build.iloc[test,:]\n",
    "        y_train_cv, y_test_cv = y_train_build.iloc[train],y_train_build.iloc[test]\n",
    "        \n",
    "        \n",
    "        for j in np.arange(0,C_range.size):\n",
    "            \n",
    "            svm_cv = LinearSVC(penalty='l1',dual=False,C=C_range[j]).fit(X_train_cv,y_train_cv)\n",
    "            \n",
    "            y_test_cv_predicted = svm_cv.predict(X_test_cv)\n",
    "            \n",
    "            mis_loc = 0\n",
    "            \n",
    "            for l in np.arange(0,X_test_cv.shape[0]):\n",
    "                \n",
    "                if y_test_cv_predicted[l] != y_test_cv.iloc[l]:\n",
    "                    \n",
    "                    mis_loc = mis_loc + 1\n",
    "                    \n",
    "            err_loc = (mis_loc/X_test_cv.shape[0])*100\n",
    "            \n",
    "            CV_errors_df.iloc[cv_ite,j] = err_loc\n",
    "            \n",
    "    \n",
    "    \n",
    "    CV_mean_errors = CV_errors_df.mean(axis=0)\n",
    "    \n",
    "    error_vector = CV_mean_errors.to_numpy().flatten()\n",
    "    \n",
    "    indx_C_selected = np.argmin(error_vector)\n",
    "    \n",
    "    min_C = C_range[indx_C_selected]\n",
    "        \n",
    "    \n",
    "    \n",
    "    svm_f = LinearSVC(penalty='l1',dual=False,C=min_C).fit(X_train_build,y_train_build)\n",
    "    \n",
    "    y_test_predicted = svm_f.predict(X_test)\n",
    "    \n",
    "    mis = 0\n",
    "    \n",
    "    for k in np.arange(0,X_test.shape[0]):\n",
    "        \n",
    "        if y_test_predicted[k] != y_test.iloc[k]:\n",
    "            \n",
    "            mis = mis + 1\n",
    "        \n",
    "    err = (mis/X_test.shape[0])*100\n",
    "    \n",
    "    \n",
    "    Error_Test_df.iloc[0,i-1] = err\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "print(Error_Test_df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above result is for a single M=1 iteration, where all the 90 errors have been obtained"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
