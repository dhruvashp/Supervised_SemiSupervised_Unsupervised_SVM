{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW6\n",
    "Spectral Clustering\n",
    "Single Monte Carlo Iteration\n",
    "\n",
    "Additionally for simplicity, gamma will be chosen 1 rather than finding a gamma that 'balances' the clusters in line with the original train\n",
    "\n",
    "NOTE :\n",
    "Data is NORMALIZED here\n",
    "\n",
    "Spectral Clustering without Normalization gave weird results with larger run times (only single cluster was obtained, despite n_clusters = 2)\n",
    "\n",
    "THUS\n",
    "Data for Spectral Clustering will be taken as NORMALIZED, again, only ONCE\n",
    "\n",
    "For KMeans, we performed all the operations over RAW data\n",
    "For Comparison, and if time permits, we may perform KMeans again with normalized data\n",
    "\n",
    "\n",
    "Data, here, for Spectral Clustering, ONCE WHOLE a priori NORMALIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0    0.016129  0.019645  0.105206  0.646400  0.000098  0.000120  0.000140   \n",
      "1    0.013871  0.012063  0.089169  0.649979  0.000073  0.000063  0.000031   \n",
      "2    0.015547  0.022945  0.099711  0.583676  0.000118  0.000091  0.000056   \n",
      "3    0.015343  0.019407  0.097872  0.632479  0.000091  0.000065  0.000025   \n",
      "4    0.012479  0.013833  0.080621  0.633850  0.000073  0.000064  0.000044   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "352  0.017087  0.026370  0.111113  0.621093  0.000135  0.000166  0.000095   \n",
      "353  0.023793  0.041898  0.156159  0.651858  0.000252  0.000330  0.000246   \n",
      "354  0.016420  0.021414  0.105291  0.606570  0.000133  0.000098  0.000057   \n",
      "355  0.017271  0.016378  0.111015  0.610479  0.000142  0.000101  0.000053   \n",
      "356  0.013891  0.022823  0.089856  0.629665  0.000085  0.000082  0.000029   \n",
      "\n",
      "           X8        X9       X10  ...       X22       X23       X24  \\\n",
      "0    0.000042  0.000179  0.000074  ...  0.024637  0.115266  0.745249   \n",
      "1    0.000024  0.000157  0.000051  ...  0.014364  0.095424  0.747960   \n",
      "2    0.000026  0.000216  0.000075  ...  0.030610  0.119498  0.795297   \n",
      "3    0.000017  0.000189  0.000065  ...  0.024846  0.107352  0.759685   \n",
      "4    0.000037  0.000113  0.000042  ...  0.019248  0.088638  0.763101   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "352  0.000045  0.000283  0.000091  ...  0.038944  0.123874  0.763361   \n",
      "353  0.000061  0.000347  0.000190  ...  0.045380  0.168388  0.717789   \n",
      "354  0.000025  0.000284  0.000082  ...  0.034071  0.120110  0.777061   \n",
      "355  0.000040  0.000252  0.000093  ...  0.024174  0.126758  0.772748   \n",
      "356  0.000028  0.000160  0.000056  ...  0.027659  0.097771  0.763636   \n",
      "\n",
      "          X25       X26       X27       X28       X29       X30  y  \n",
      "0    0.000124  0.000290  0.000418  0.000127  0.000250  0.000089  0  \n",
      "1    0.000103  0.000159  0.000124  0.000075  0.000227  0.000062  0  \n",
      "2    0.000174  0.000276  0.000307  0.000112  0.000410  0.000095  0  \n",
      "3    0.000139  0.000192  0.000156  0.000080  0.000314  0.000087  0  \n",
      "4    0.000101  0.000127  0.000126  0.000069  0.000181  0.000049  0  \n",
      "..        ...       ...       ...       ...       ...       ... ..  \n",
      "352  0.000202  0.000438  0.000403  0.000164  0.000488  0.000120  0  \n",
      "353  0.000313  0.000500  0.000410  0.000102  0.000439  0.000205  0  \n",
      "354  0.000188  0.000274  0.000310  0.000104  0.000462  0.000108  0  \n",
      "355  0.000234  0.000362  0.000318  0.000136  0.000457  0.000129  0  \n",
      "356  0.000106  0.000168  0.000087  0.000066  0.000240  0.000069  0  \n",
      "\n",
      "[357 rows x 31 columns]\n",
      "           X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0    0.008571  0.008335  0.056097  0.562184  0.000039  0.000048  0.000064   \n",
      "1    0.013776  0.020399  0.089808  0.652673  0.000082  0.000093  0.000101   \n",
      "2    0.010503  0.013403  0.068463  0.638519  0.000055  0.000053  0.000089   \n",
      "3    0.012823  0.020770  0.084504  0.579814  0.000102  0.000128  0.000110   \n",
      "4    0.009434  0.008441  0.062823  0.525789  0.000056  0.000112  0.000088   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "207  0.015863  0.022289  0.106188  0.580747  0.000147  0.000229  0.000223   \n",
      "208  0.017418  0.029601  0.115230  0.568449  0.000191  0.000339  0.000266   \n",
      "209  0.010822  0.012125  0.070601  0.546133  0.000065  0.000076  0.000063   \n",
      "210  0.012461  0.014645  0.080727  0.565211  0.000097  0.000109  0.000128   \n",
      "211  0.007925  0.004573  0.054099  0.440986  0.000052  0.000122  0.000132   \n",
      "\n",
      "           X8        X9       X10  ...       X22       X23       X24  \\\n",
      "0    0.000047  0.000063  0.000023  ...  0.013027  0.068323  0.821342   \n",
      "1    0.000067  0.000154  0.000055  ...  0.023160  0.096350  0.744721   \n",
      "2    0.000049  0.000089  0.000029  ...  0.016598  0.074950  0.761827   \n",
      "3    0.000078  0.000169  0.000058  ...  0.028969  0.099426  0.802613   \n",
      "4    0.000056  0.000112  0.000035  ...  0.009883  0.078450  0.841472   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "207  0.000100  0.000360  0.000099  ...  0.035463  0.123584  0.795435   \n",
      "208  0.000100  0.000345  0.000125  ...  0.051594  0.144250  0.798753   \n",
      "209  0.000040  0.000125  0.000042  ...  0.016975  0.086656  0.828268   \n",
      "210  0.000072  0.000163  0.000052  ...  0.017862  0.101190  0.809683   \n",
      "211  0.000065  0.000107  0.000035  ...  0.007635  0.081325  0.889462   \n",
      "\n",
      "          X25       X26       X27       X28       X29       X30  y  \n",
      "0    0.000056  0.000126  0.000179  0.000093  0.000092  0.000030  1  \n",
      "1    0.000113  0.000179  0.000255  0.000132  0.000229  0.000061  1  \n",
      "2    0.000082  0.000099  0.000213  0.000079  0.000123  0.000033  1  \n",
      "3    0.000143  0.000296  0.000262  0.000140  0.000288  0.000077  1  \n",
      "4    0.000077  0.000294  0.000198  0.000110  0.000196  0.000058  1  \n",
      "..        ...       ...       ...       ...       ...       ... ..  \n",
      "207  0.000186  0.000550  0.000605  0.000251  0.000776  0.000138  1  \n",
      "208  0.000343  0.001474  0.001321  0.000397  0.000653  0.000221  1  \n",
      "209  0.000088  0.000150  0.000188  0.000082  0.000188  0.000055  1  \n",
      "210  0.000118  0.000180  0.000280  0.000139  0.000285  0.000060  1  \n",
      "211  0.000071  0.000293  0.000314  0.000117  0.000203  0.000052  1  \n",
      "\n",
      "[212 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  \n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "df = pd.read_csv('wdbc.csv', header = None)\n",
    "\n",
    "\n",
    "output = df.iloc[:,0]\n",
    "\n",
    "\n",
    "for i in np.arange(0,df.shape[0]):\n",
    "    if output.iloc[i] == 'B':\n",
    "        output.iloc[i] = 0\n",
    "    else:\n",
    "        output.iloc[i] = 1\n",
    "\n",
    "\n",
    "\n",
    "features = df.iloc[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "features_normal = normalize(features)\n",
    "\n",
    "\n",
    "features_normal_df = pd.DataFrame(features_normal)\n",
    "\n",
    "\n",
    "norm_whole = pd.concat([features_normal_df,output],axis=1)\n",
    "\n",
    "\n",
    "col_head = norm_whole.columns\n",
    "\n",
    "\n",
    "norm_whole.columns= ['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10','X11','X12','X13','X14','X15','X16','X17','X18','X19','X20','X21','X22','X23','X24','X25','X26','X27','X28','X29','X30','y']\n",
    "\n",
    "\n",
    "norm_whole.sort_values(by=['y'],inplace=True)\n",
    "\n",
    "\n",
    "norm_whole.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "X_y_0 = norm_whole.iloc[0:357,:]\n",
    "X_y_1 = norm_whole.iloc[357:569,:]\n",
    "X_y_1.reset_index(drop=True,inplace=True)\n",
    "\n",
    "print(X_y_0)             \n",
    "print(X_y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0    0.012712  0.019313  0.083631  0.535813  0.000110  0.000153  0.000087   \n",
      "1    0.017223  0.030666  0.110656  0.628386  0.000142  0.000118  0.000037   \n",
      "2    0.017032  0.031194  0.109796  0.597249  0.000164  0.000139  0.000068   \n",
      "3    0.016420  0.021414  0.105291  0.606570  0.000133  0.000098  0.000057   \n",
      "4    0.009222  0.012803  0.060743  0.547744  0.000049  0.000070  0.000092   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "449  0.018629  0.025192  0.119247  0.628884  0.000135  0.000119  0.000060   \n",
      "450  0.013891  0.022823  0.089856  0.629665  0.000085  0.000082  0.000029   \n",
      "451  0.013510  0.016500  0.088482  0.582980  0.000106  0.000124  0.000095   \n",
      "452  0.008610  0.009831  0.056378  0.500936  0.000042  0.000064  0.000049   \n",
      "453  0.016406  0.023998  0.104639  0.600502  0.000126  0.000087  0.000040   \n",
      "\n",
      "           X8        X9       X10  ...       X21       X22       X23  \\\n",
      "0    0.000055  0.000204  0.000069  ...  0.015818  0.026091  0.102545   \n",
      "1    0.000032  0.000292  0.000091  ...  0.018904  0.039415  0.123258   \n",
      "2    0.000033  0.000274  0.000104  ...  0.019502  0.047839  0.125742   \n",
      "3    0.000025  0.000284  0.000082  ...  0.018705  0.034071  0.120110   \n",
      "4    0.000047  0.000092  0.000030  ...  0.011417  0.017279  0.076915   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "449  0.000035  0.000338  0.000105  ...  0.020400  0.035148  0.134534   \n",
      "450  0.000028  0.000160  0.000056  ...  0.015307  0.027659  0.097771   \n",
      "451  0.000051  0.000185  0.000059  ...  0.015862  0.021359  0.104615   \n",
      "452  0.000028  0.000090  0.000028  ...  0.011257  0.015767  0.073902   \n",
      "453  0.000023  0.000257  0.000084  ...  0.018701  0.034050  0.119572   \n",
      "\n",
      "          X24       X25       X26       X27       X28       X29       X30  \n",
      "0    0.831674  0.000153  0.000341  0.000248  0.000144  0.000296  0.000107  \n",
      "1    0.757453  0.000207  0.000317  0.000169  0.000120  0.000445  0.000106  \n",
      "2    0.781110  0.000232  0.000249  0.000261  0.000091  0.000411  0.000132  \n",
      "3    0.777061  0.000188  0.000274  0.000310  0.000104  0.000462  0.000108  \n",
      "4    0.829798  0.000086  0.000185  0.000277  0.000090  0.000157  0.000047  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "449  0.754424  0.000185  0.000334  0.000262  0.000114  0.000540  0.000123  \n",
      "450  0.763636  0.000106  0.000168  0.000087  0.000066  0.000240  0.000069  \n",
      "451  0.799371  0.000146  0.000316  0.000311  0.000133  0.000297  0.000077  \n",
      "452  0.859205  0.000069  0.000221  0.000213  0.000094  0.000169  0.000045  \n",
      "453  0.781389  0.000173  0.000240  0.000201  0.000074  0.000386  0.000113  \n",
      "\n",
      "[454 rows x 30 columns]\n",
      "0      1\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      1\n",
      "      ..\n",
      "449    0\n",
      "450    0\n",
      "451    1\n",
      "452    1\n",
      "453    0\n",
      "Name: y, Length: 454, dtype: int32\n",
      "           X1        X2        X3        X4        X5        X6        X7  \\\n",
      "0    0.009434  0.008441  0.062823  0.525789  0.000056  0.000112  0.000088   \n",
      "1    0.016894  0.018418  0.109595  0.631681  0.000148  0.000132  0.000040   \n",
      "2    0.016129  0.019645  0.105206  0.646400  0.000098  0.000120  0.000140   \n",
      "3    0.009789  0.011627  0.069705  0.603916  0.000062  0.000168  0.000182   \n",
      "4    0.013652  0.020643  0.093551  0.627643  0.000091  0.000204  0.000250   \n",
      "..        ...       ...       ...       ...       ...       ...       ...   \n",
      "110  0.011037  0.014235  0.072591  0.573274  0.000063  0.000088  0.000089   \n",
      "111  0.006925  0.008892  0.045750  0.376233  0.000047  0.000061  0.000063   \n",
      "112  0.012735  0.025091  0.081401  0.605604  0.000070  0.000039  0.000039   \n",
      "113  0.007068  0.006070  0.046560  0.514888  0.000029  0.000039  0.000051   \n",
      "114  0.009181  0.011011  0.062755  0.591130  0.000048  0.000098  0.000139   \n",
      "\n",
      "           X8        X9       X10  ...       X21       X22       X23  \\\n",
      "0    0.000056  0.000112  0.000035  ...  0.011702  0.009883  0.078450   \n",
      "1    0.000040  0.000261  0.000090  ...  0.018488  0.024682  0.126641   \n",
      "2    0.000042  0.000179  0.000074  ...  0.017392  0.024637  0.115266   \n",
      "3    0.000078  0.000141  0.000039  ...  0.011336  0.015387  0.082608   \n",
      "4    0.000089  0.000187  0.000063  ...  0.014981  0.025261  0.114900   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "110  0.000040  0.000125  0.000037  ...  0.013193  0.019133  0.088019   \n",
      "111  0.000038  0.000083  0.000026  ...  0.011005  0.013126  0.073616   \n",
      "112  0.000023  0.000156  0.000045  ...  0.014528  0.031067  0.092671   \n",
      "113  0.000031  0.000046  0.000017  ...  0.009425  0.007307  0.064744   \n",
      "114  0.000065  0.000094  0.000030  ...  0.010660  0.012907  0.078598   \n",
      "\n",
      "          X24       X25       X26       X27       X28       X29       X30  \n",
      "0    0.841472  0.000077  0.000294  0.000198  0.000110  0.000196  0.000058  \n",
      "1    0.755578  0.000198  0.000358  0.000137  0.000113  0.000481  0.000128  \n",
      "2    0.745249  0.000124  0.000290  0.000418  0.000127  0.000250  0.000089  \n",
      "3    0.787273  0.000080  0.000299  0.000373  0.000122  0.000264  0.000048  \n",
      "4    0.762976  0.000130  0.000650  0.000826  0.000227  0.000263  0.000106  \n",
      "..        ...       ...       ...       ...       ...       ...       ...  \n",
      "110  0.810298  0.000103  0.000253  0.000357  0.000120  0.000321  0.000057  \n",
      "111  0.921243  0.000075  0.000149  0.000195  0.000087  0.000150  0.000040  \n",
      "112  0.783960  0.000097  0.000083  0.000130  0.000055  0.000272  0.000052  \n",
      "113  0.851616  0.000037  0.000111  0.000116  0.000069  0.000089  0.000022  \n",
      "114  0.798267  0.000062  0.000184  0.000290  0.000112  0.000129  0.000043  \n",
      "\n",
      "[115 rows x 30 columns]\n",
      "0      1\n",
      "1      0\n",
      "2      0\n",
      "3      1\n",
      "4      1\n",
      "      ..\n",
      "110    1\n",
      "111    1\n",
      "112    1\n",
      "113    1\n",
      "114    1\n",
      "Name: y, Length: 115, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_y_train_0,X_y_test_0 = train_test_split(X_y_0,test_size = 0.2,shuffle=True)\n",
    "X_y_train_1,X_y_test_1 = train_test_split(X_y_1,test_size = 0.2,shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "X_y_train = pd.concat([X_y_train_0,X_y_train_1],axis=0)\n",
    "X_y_test = pd.concat([X_y_test_0,X_y_test_1],axis=0)\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_y_train = shuffle(X_y_train)\n",
    "X_y_test = shuffle(X_y_test)\n",
    "\n",
    "\n",
    "\n",
    "X_y_train.reset_index(drop=True,inplace=True)\n",
    "X_y_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "X_train = X_y_train.drop(columns=['y'])\n",
    "X_test = X_y_test.drop(columns=['y'])\n",
    "y_train = X_y_train['y'].astype(int)\n",
    "y_test =  X_y_test['y'].astype(int)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_test)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0\n",
      " 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0\n",
      " 1 0 1 0 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "specclus = SpectralClustering(n_clusters=2,gamma=1,affinity='rbf',n_init=10).fit(X_train)  # gamma selected as 1 for simplicity\n",
    "\n",
    "\n",
    "    \n",
    "# NOTE : Both KMeans and SpectralCLustering have n_init = 10. As such the external loop is not required.\n",
    "# FOR KMeans ---- The external loop was used, to increase chances of global optimal even more\n",
    "# In KMeans, thus, each external iteration has 10 more internal iterations, and we assume that by the final iteration\n",
    "# (where again KMeans will be internally done 10 more times) the algorithm has converged, or the overall chances of the \n",
    "# algorithm converging have increased\n",
    "\n",
    "# FOR SpectralClustering : External loop, again, as such not needed, could be used like it was in KMeans to increase\n",
    "# chances of convergence even more (convergence to global optimal assumed as we reach the final iteration)\n",
    "\n",
    "# However the external loop for SpectralClustering, hasn't been used, as it does increase the run times \n",
    "# As is, the external loop was not completely necessary, as internally, both KMeans and SpectralClustering, run the \n",
    "# loops multiple times to pick the most minimal inertia fit (global optimal) (objective function) over all the times\n",
    "\n",
    "# In conclusion : external loop may be used, though not completely necessary, as the functions do it internally, and for KMeans\n",
    "# it has been used, but for SpectralClustering, hasn't been used, due to large run times in general.\n",
    "\n",
    "y_train_pred_cluster = specclus.labels_\n",
    "\n",
    "print(y_train_pred_cluster)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   2   3   5   6   8   9  10  12  13  15  17  18  19  20  21  22  23\n",
      "  24  27  28  30  31  32  33  34  36  37  38  39  41  44  47  49  50  53\n",
      "  54  55  58  60  61  62  63  64  66  69  70  71  72  73  74  76  77  78\n",
      "  79  80  81  83  86  88  89  90  91  92  93  94  95  96  98 100 102 103\n",
      " 105 107 108 109 110 111 112 113 114 115 119 120 121 122 123 124 125 126\n",
      " 127 129 130 131 132 134 136 137 138 140 143 145 146 147 148 152 154 155\n",
      " 156 158 159 160 162 163 167 169 170 172 173 174 175 176 177 178 180 181\n",
      " 183 184 187 189 190 191 192 193 195 197 198 199 200 201 202 203 204 206\n",
      " 207 208 209 210 213 214 215 216 219 220 221 222 223 226 227 228 229 231\n",
      " 232 234 235 236 238 239 242 243 246 248 249 253 254 256 258 259 261 262\n",
      " 263 264 265 267 268 269 271 272 273 274 275 276 277 278 279 281 283 284\n",
      " 286 287 288 290 291 292 293 295 296 297 299 300 301 302 303 304 305 306\n",
      " 307 309 310 311 313 314 315 316 317 318 319 320 321 323 324 325 326 327\n",
      " 328 329 331 332 333 334 335 336 337 339 340 342 343 344 345 346 349 350\n",
      " 351 352 353 355 357 359 360 361 362 363 364 365 366 367 368 369 371 372\n",
      " 373 374 375 377 378 380 382 383 384 385 386 387 390 391 392 394 396 397\n",
      " 398 399 400 404 406 407 408 409 410 411 412 414 415 416 418 419 422 423\n",
      " 424 425 429 432 433 435 436 438 439 441 442 443 445 447 448 449 450 453]\n",
      "[  0   4   7  11  14  16  25  26  29  35  40  42  43  45  46  48  51  52\n",
      "  56  57  59  65  67  68  75  82  84  85  87  97  99 101 104 106 116 117\n",
      " 118 128 133 135 139 141 142 144 149 150 151 153 157 161 164 165 166 168\n",
      " 171 179 182 185 186 188 194 196 205 211 212 217 218 224 225 230 233 237\n",
      " 240 241 244 245 247 250 251 252 255 257 260 266 270 280 282 285 289 294\n",
      " 298 308 312 322 330 338 341 347 348 354 356 358 370 376 379 381 388 389\n",
      " 393 395 401 402 403 405 413 417 420 421 426 427 428 430 431 434 437 440\n",
      " 444 446 451 452]\n"
     ]
    }
   ],
   "source": [
    "# Polling will be done over all the cluster points in each cluster\n",
    "\n",
    "all_indx = np.arange(0,X_train.shape[0])\n",
    "\n",
    "\n",
    "list_cluster_0 = []        \n",
    "list_cluster_1 = []         \n",
    "\n",
    "for i in all_indx:\n",
    "    if y_train_pred_cluster[i] == 0:\n",
    "        list_cluster_0.append(i)\n",
    "    else:\n",
    "        list_cluster_1.append(i)\n",
    "        \n",
    "\n",
    "sel_indx_0_cls = np.array(list_cluster_0).flatten()  # sel_indx_0_cls contains indices of ALL samples in cluster 0\n",
    "sel_indx_1_cls = np.array(list_cluster_1).flatten()  # sel_indx_1_cls contains indices of ALL samples in cluster 1\n",
    "\n",
    "print(sel_indx_0_cls)\n",
    "print(sel_indx_1_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "5      0\n",
      "6      0\n",
      "      ..\n",
      "447    0\n",
      "448    0\n",
      "449    0\n",
      "450    0\n",
      "453    0\n",
      "Name: y, Length: 324, dtype: int32\n",
      "0      1\n",
      "4      1\n",
      "7      1\n",
      "11     1\n",
      "14     1\n",
      "      ..\n",
      "440    1\n",
      "444    1\n",
      "446    1\n",
      "451    1\n",
      "452    1\n",
      "Name: y, Length: 130, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "y_train_read_0 = y_train[sel_indx_0_cls]    # has true labels of all samples in cluster 0\n",
    "y_train_read_1 = y_train[sel_indx_1_cls]    # has true labels of all samples in cluster 1\n",
    "\n",
    "print(y_train_read_0)\n",
    "print(y_train_read_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "pol_thrsh = 0.5 \n",
    "\n",
    "read_labels_0 = y_train_read_0.to_numpy().flatten()   \n",
    "read_labels_1 = y_train_read_1.to_numpy().flatten()   \n",
    "\n",
    "pol_num_0 = math.floor(pol_thrsh*read_labels_0.size)    \n",
    "pol_num_1 = math.floor(pol_thrsh*read_labels_1.size)     \n",
    "\n",
    "\n",
    "pol_cnt_c0_0 = 0                   \n",
    "pol_cnt_c1_0 = 0                   \n",
    "\n",
    "for i in np.arange(0,read_labels_0.size):\n",
    "    if read_labels_0[i] == 0:\n",
    "        pol_cnt_c0_0 = pol_cnt_c0_0 + 1\n",
    "        \n",
    "\n",
    "if pol_cnt_c0_0 > pol_num_0:\n",
    "    clus_0 = 0\n",
    "else:\n",
    "    clus_0 = 1\n",
    "    \n",
    "\n",
    "\n",
    "for i in np.arange(0,read_labels_1.size):\n",
    "    if read_labels_1[i] == 0:\n",
    "        pol_cnt_c1_0 = pol_cnt_c1_0 + 1\n",
    "        \n",
    "\n",
    "if pol_cnt_c1_0 > pol_num_1:\n",
    "    clus_1 = 0\n",
    "else:\n",
    "    clus_1 = 1\n",
    "    \n",
    "\n",
    "    \n",
    "print(clus_0)\n",
    "print(clus_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 1 1 0 1 1 0 1 0 0 1 1 0 0 0 1 1 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 1 1 0 1 0 0 0\n",
      " 0 1 1 1 0 1 0 0 0 1 0 0 0 1 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0\n",
      " 1 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0\n",
      " 0 0 1 1 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 0 0 1 1 1 0 0 1 0 1 0\n",
      " 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 1 0 0 0 0 0 1 1 1 0 1 0\n",
      " 0 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 1 0 0 1 0 0 0\n",
      " 1 0 1 0 0 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = np.zeros(X_train.shape[0])\n",
    "\n",
    "for i in np.arange(0,X_train.shape[0]):\n",
    "    if y_train_pred_cluster[i] == 0:\n",
    "        y_train_pred[i] = clus_0\n",
    "    else:\n",
    "        y_train_pred[i] = clus_1\n",
    "        \n",
    "y_train_pred = y_train_pred.astype(int)\n",
    "print(y_train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error is : \n",
      " 11.233480176211454 %\n"
     ]
    }
   ],
   "source": [
    "mis = 0\n",
    "for l in np.arange(0,X_train.shape[0]):\n",
    "    if y_train_pred[l] != y_train.iloc[l]:\n",
    "        mis = mis + 1\n",
    "\n",
    "train_error = (mis/X_train.shape[0])*100\n",
    "print('The training error is : \\n',train_error,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for training is : \n",
      " [[279   6]\n",
      " [ 45 124]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix_train = confusion_matrix(y_train,y_train_pred)\n",
    "\n",
    "print('The confusion matrix for training is : \\n',confusion_matrix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for train, appropriately indexed is : \n",
      "             Predicted 0  Predicted 1\n",
      "Actually 0          279            6\n",
      "Actually 1           45          124\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_train_df = pd.DataFrame(confusion_matrix_train,index=['Actually 0','Actually 1'],columns=['Predicted 0','Predicted 1'])\n",
    "print('The confusion matrix for train, appropriately indexed is : \\n',confusion_matrix_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision for train is : \n",
      " 95.38461538461539 %\n",
      "The recall for train is : \n",
      " 73.37278106508876 %\n"
     ]
    }
   ],
   "source": [
    "precision_train = (confusion_matrix_train[1][1]/(confusion_matrix_train[1][1]+confusion_matrix_train[0][1]))*100\n",
    "recall_train = (confusion_matrix_train[1][1]/(confusion_matrix_train[1][1]+confusion_matrix_train[1][0]))*100\n",
    "\n",
    "print('The precision for train is : \\n',precision_train,'%')\n",
    "print('The recall for train is : \\n',recall_train,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for training is : \n",
      " 88.76651982378854 %\n",
      "The f1 score for training is : \n",
      " 0.8294314381270904\n"
     ]
    }
   ],
   "source": [
    "accuracy_train = ((confusion_matrix_train[0][0]+confusion_matrix_train[1][1])/(confusion_matrix_train[0][0]+confusion_matrix_train[1][1]+confusion_matrix_train[0][1]+confusion_matrix_train[1][0]))*100\n",
    "f1_train = ((2*(precision_train/100)*(recall_train/100))/((precision_train/100)+(recall_train/100))) # divided by 100 as precision and recall specified in percentage\n",
    "print('The accuracy for training is : \\n',accuracy_train,'%')\n",
    "print('The f1 score for training is : \\n',f1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1\n",
      " 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=1).fit(X_train,y_train_pred_cluster)       # KNN to obtain test cluster assignment, classify test point to the cluster of the point closest to it\n",
    "y_test_pred_cluster = neigh.predict(X_test)\n",
    "\n",
    "print(y_test_pred_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1\n",
      " 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = np.zeros(X_test.shape[0])\n",
    "for i in np.arange(0,X_test.shape[0]):\n",
    "    if y_test_pred_cluster[i] == 0:\n",
    "        y_test_pred[i] = clus_0\n",
    "    else:\n",
    "        y_test_pred[i] = clus_1\n",
    "\n",
    "y_test_pred = y_test_pred.astype(int)\n",
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test error is obtained : \n",
      " 13.91304347826087 %\n"
     ]
    }
   ],
   "source": [
    "mis = 0\n",
    "for l in np.arange(0,X_test.shape[0]):\n",
    "    if y_test_pred[l] != y_test.iloc[l]:\n",
    "        mis = mis + 1\n",
    "\n",
    "test_error = (mis/X_test.shape[0])*100\n",
    "print('The test error is obtained : \\n',test_error,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for test is : \n",
      " [[70  2]\n",
      " [14 29]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_test = confusion_matrix(y_test,y_test_pred)\n",
    "\n",
    "print('The confusion matrix for test is : \\n',confusion_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix for test, appropriately indexed is : \n",
      "             Predicted 0  Predicted 1\n",
      "Actually 0           70            2\n",
      "Actually 1           14           29\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_test_df = pd.DataFrame(confusion_matrix_test,index=['Actually 0','Actually 1'],columns=['Predicted 0','Predicted 1'])\n",
    "print('The confusion matrix for test, appropriately indexed is : \\n',confusion_matrix_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The precision for test is : \n",
      " 93.54838709677419 %\n",
      "The recall for test is : \n",
      " 67.44186046511628 %\n"
     ]
    }
   ],
   "source": [
    "precision_test = (confusion_matrix_test[1][1]/(confusion_matrix_test[1][1]+confusion_matrix_test[0][1]))*100\n",
    "recall_test = (confusion_matrix_test[1][1]/(confusion_matrix_test[1][1]+confusion_matrix_test[1][0]))*100\n",
    "\n",
    "print('The precision for test is : \\n',precision_test,'%')\n",
    "print('The recall for test is : \\n',recall_test,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for test is : \n",
      " 86.08695652173914 %\n",
      "The f1 score for test is : \n",
      " 0.7837837837837838\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = ((confusion_matrix_test[0][0]+confusion_matrix_test[1][1])/(confusion_matrix_test[0][0]+confusion_matrix_test[1][1]+confusion_matrix_test[0][1]+confusion_matrix_test[1][0]))*100\n",
    "f1_test = ((2*(precision_test/100)*(recall_test/100))/((precision_test/100)+(recall_test/100)))\n",
    "print('The accuracy for test is : \\n',accuracy_test,'%')\n",
    "print('The f1 score for test is : \\n',f1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     FPR TPR\n",
      "0.00   0   0\n",
      "0.01   0   0\n",
      "0.02   0   0\n",
      "0.03   0   0\n",
      "0.04   0   0\n",
      "...   ..  ..\n",
      "0.96   1   1\n",
      "0.97   1   1\n",
      "0.98   1   1\n",
      "0.99   1   1\n",
      "1.00   1   1\n",
      "\n",
      "[101 rows x 2 columns]\n",
      "     FPR TPR\n",
      "0.00   0   0\n",
      "0.01   0   0\n",
      "0.02   0   0\n",
      "0.03   0   0\n",
      "0.04   0   0\n",
      "...   ..  ..\n",
      "0.96   1   1\n",
      "0.97   1   1\n",
      "0.98   1   1\n",
      "0.99   1   1\n",
      "1.00   1   1\n",
      "\n",
      "[101 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "pol_thrsh_ra_range = np.arange(0,1.01,0.01)  \n",
    "ROC_df = pd.DataFrame(index=pol_thrsh_ra_range,columns=['FPR','TPR'])\n",
    "ROC_df_test = pd.DataFrame(index=pol_thrsh_ra_range,columns=['FPR','TPR'])\n",
    "\n",
    "\n",
    "\n",
    "for ra in np.arange(0,pol_thrsh_ra_range.size):\n",
    "    \n",
    "    pol_thrsh_ra = pol_thrsh_ra_range[ra]\n",
    "    \n",
    "    pol_num_0_ra = math.floor(pol_thrsh_ra*read_labels_0.size)    \n",
    "    pol_num_1_ra = math.floor(pol_thrsh_ra*read_labels_1.size)\n",
    "    \n",
    "    pol_cnt_c0_0_ra = 0                    \n",
    "    pol_cnt_c1_0_ra = 0                    \n",
    "\n",
    "\n",
    "    for i in np.arange(0,read_labels_0.size):\n",
    "        if read_labels_0[i] == 0:\n",
    "            pol_cnt_c0_0_ra = pol_cnt_c0_0_ra + 1\n",
    "\n",
    "\n",
    "    if pol_cnt_c0_0_ra > pol_num_0_ra:\n",
    "        clus_0_ra = 0\n",
    "    else:\n",
    "        clus_0_ra = 1\n",
    "\n",
    "\n",
    "\n",
    "    for i in np.arange(0,read_labels_1.size):\n",
    "        if read_labels_1[i] == 0:\n",
    "            pol_cnt_c1_0_ra = pol_cnt_c1_0_ra + 1\n",
    "\n",
    "\n",
    "    if pol_cnt_c1_0_ra > pol_num_1_ra:\n",
    "        clus_1_ra = 0\n",
    "    else:\n",
    "        clus_1_ra = 1\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    y_train_pred_ra = np.zeros(X_train.shape[0])\n",
    "\n",
    "    for i in np.arange(0,X_train.shape[0]):\n",
    "        if y_train_pred_cluster[i] == 0:\n",
    "            y_train_pred_ra[i] = clus_0_ra\n",
    "        else:\n",
    "            y_train_pred_ra[i] = clus_1_ra\n",
    "\n",
    "    y_train_pred_ra = y_train_pred_ra.astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    y_test_pred_ra = np.zeros(X_test.shape[0])\n",
    "    for i in np.arange(0,X_test.shape[0]):\n",
    "        if y_test_pred_cluster[i] == 0:\n",
    "            y_test_pred_ra[i] = clus_0_ra\n",
    "        else:\n",
    "            y_test_pred_ra[i] = clus_1_ra\n",
    "\n",
    "    y_test_pred_ra = y_test_pred_ra.astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "    confusion_matrix_train_ra = confusion_matrix(y_train,y_train_pred_ra)\n",
    "    ROC_df.iloc[ra,0] = confusion_matrix_train_ra[0][1]/(confusion_matrix_train_ra[0][1]+confusion_matrix_train_ra[0][0])\n",
    "    ROC_df.iloc[ra,1] = confusion_matrix_train_ra[1][1]/(confusion_matrix_train_ra[1][1]+confusion_matrix_train_ra[1][0])\n",
    "    \n",
    "    \n",
    "    confusion_matrix_test_ra = confusion_matrix(y_test,y_test_pred_ra)\n",
    "    ROC_df_test.iloc[ra,0] = confusion_matrix_test_ra[0][1]/(confusion_matrix_test_ra[0][1]+confusion_matrix_test_ra[0][0])\n",
    "    ROC_df_test.iloc[ra,1] = confusion_matrix_test_ra[1][1]/(confusion_matrix_test_ra[1][1]+confusion_matrix_test_ra[1][0])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "print(ROC_df)\n",
    "print(ROC_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'TPR for Train')"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(ROC_df['FPR'],ROC_df['TPR'])\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('FPR for Train')\n",
    "plt.ylabel('TPR for Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'TPR for Test')"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ROC_df_test['FPR'],ROC_df_test['TPR'])\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('FPR for Test')\n",
    "plt.ylabel('TPR for Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for train is : \n",
      " 0.8563375895359702\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "AUC_train = metrics.auc(ROC_df['FPR'],ROC_df['TPR'])\n",
    "print('The AUC for train is : \\n',AUC_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC for test is : \n",
      " 0.8233204134366924\n"
     ]
    }
   ],
   "source": [
    "AUC_test = metrics.auc(ROC_df_test['FPR'],ROC_df_test['TPR'])\n",
    "print('The AUC for test is : \\n',AUC_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
