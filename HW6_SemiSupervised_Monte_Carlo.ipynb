{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "The best C, penalty, selected for each Monte Carlo iterations is :\n",
      "    Selected Penalty\n",
      "1            100000\n",
      "2             1e+06\n",
      "3             1e+07\n",
      "4             1e+07\n",
      "5             10000\n",
      "6             10000\n",
      "7             1e+07\n",
      "8            100000\n",
      "9             1e+06\n",
      "10           100000\n",
      "11            1e+06\n",
      "12           100000\n",
      "13             1000\n",
      "14            1e+06\n",
      "15            10000\n",
      "16            1e+06\n",
      "17            10000\n",
      "18           100000\n",
      "19            10000\n",
      "20            1e+07\n",
      "21            1e+06\n",
      "22             1000\n",
      "23            10000\n",
      "24            10000\n",
      "25            10000\n",
      "26            10000\n",
      "27           100000\n",
      "28            1e+06\n",
      "29           100000\n",
      "30            1e+06\n",
      "The Precision for Train for the Monte Carlo iterations (for best C) is : \n",
      "    Precision Train\n",
      "1              100\n",
      "2              100\n",
      "3              100\n",
      "4              100\n",
      "5          98.8571\n",
      "6          99.4083\n",
      "7              100\n",
      "8              100\n",
      "9              100\n",
      "10             100\n",
      "11             100\n",
      "12             100\n",
      "13         99.3865\n",
      "14             100\n",
      "15             100\n",
      "16             100\n",
      "17         98.8024\n",
      "18         99.3939\n",
      "19         99.4152\n",
      "20             100\n",
      "21             100\n",
      "22         98.2659\n",
      "23         98.8235\n",
      "24         99.4186\n",
      "25             100\n",
      "26         99.3827\n",
      "27             100\n",
      "28             100\n",
      "29             100\n",
      "30             100\n",
      "The Recall for Train for the Monte Carlo iterations (for best C) is : \n",
      "    Recall Train\n",
      "1           100\n",
      "2       98.8024\n",
      "3           100\n",
      "4           100\n",
      "5       99.4253\n",
      "6       99.4083\n",
      "7           100\n",
      "8       99.4012\n",
      "9           100\n",
      "10      99.4012\n",
      "11          100\n",
      "12      99.4118\n",
      "13      98.1818\n",
      "14          100\n",
      "15      99.3865\n",
      "16          100\n",
      "17      97.6331\n",
      "18      99.3939\n",
      "19      98.8372\n",
      "20          100\n",
      "21          100\n",
      "22      97.7011\n",
      "23      99.4083\n",
      "24      98.8439\n",
      "25      98.1928\n",
      "26       98.773\n",
      "27          100\n",
      "28      99.4083\n",
      "29          100\n",
      "30      99.4318\n",
      "The Accuracy for Train for the Monte Carlo iterations (for best C) is : \n",
      "    Accuracy Train\n",
      "1             100\n",
      "2         99.5595\n",
      "3             100\n",
      "4             100\n",
      "5         99.3392\n",
      "6         99.5595\n",
      "7             100\n",
      "8         99.7797\n",
      "9             100\n",
      "10        99.7797\n",
      "11            100\n",
      "12        99.7797\n",
      "13        99.1189\n",
      "14            100\n",
      "15        99.7797\n",
      "16            100\n",
      "17        98.6784\n",
      "18        99.5595\n",
      "19        99.3392\n",
      "20            100\n",
      "21            100\n",
      "22        98.4581\n",
      "23        99.3392\n",
      "24        99.3392\n",
      "25        99.3392\n",
      "26        99.3392\n",
      "27            100\n",
      "28        99.7797\n",
      "29            100\n",
      "30        99.7797\n",
      "The F1 for Train for the Monte Carlo iterations (for best C) is : \n",
      "     F1 Train\n",
      "1          1\n",
      "2   0.993976\n",
      "3          1\n",
      "4          1\n",
      "5   0.991404\n",
      "6   0.994083\n",
      "7          1\n",
      "8   0.996997\n",
      "9          1\n",
      "10  0.996997\n",
      "11         1\n",
      "12   0.99705\n",
      "13  0.987805\n",
      "14         1\n",
      "15  0.996923\n",
      "16         1\n",
      "17  0.982143\n",
      "18  0.993939\n",
      "19  0.991254\n",
      "20         1\n",
      "21         1\n",
      "22  0.979827\n",
      "23   0.99115\n",
      "24  0.991304\n",
      "25  0.990881\n",
      "26  0.990769\n",
      "27         1\n",
      "28  0.997033\n",
      "29         1\n",
      "30  0.997151\n",
      "The training error for the Monte Carlo iterations (for best C) is : \n",
      "    Train Error for best selected C\n",
      "1                                0\n",
      "2                         0.440529\n",
      "3                                0\n",
      "4                                0\n",
      "5                         0.660793\n",
      "6                         0.440529\n",
      "7                                0\n",
      "8                         0.220264\n",
      "9                                0\n",
      "10                        0.220264\n",
      "11                               0\n",
      "12                        0.220264\n",
      "13                        0.881057\n",
      "14                               0\n",
      "15                        0.220264\n",
      "16                               0\n",
      "17                         1.32159\n",
      "18                        0.440529\n",
      "19                        0.660793\n",
      "20                               0\n",
      "21                               0\n",
      "22                         1.54185\n",
      "23                        0.660793\n",
      "24                        0.660793\n",
      "25                        0.660793\n",
      "26                        0.660793\n",
      "27                               0\n",
      "28                        0.220264\n",
      "29                               0\n",
      "30                        0.220264\n",
      "The AUC for Train for the Monte Carlo iterations (for best C) is : \n",
      "    AUC Train\n",
      "1          1\n",
      "2          1\n",
      "3          1\n",
      "4          1\n",
      "5   0.999343\n",
      "6   0.999813\n",
      "7          1\n",
      "8   0.999948\n",
      "9          1\n",
      "10         1\n",
      "11         1\n",
      "12         1\n",
      "13  0.998721\n",
      "14         1\n",
      "15  0.999779\n",
      "16         1\n",
      "17  0.998972\n",
      "18   0.99978\n",
      "19  0.999907\n",
      "20         1\n",
      "21         1\n",
      "22   0.99649\n",
      "23  0.999917\n",
      "24  0.999774\n",
      "25  0.999801\n",
      "26  0.999842\n",
      "27         1\n",
      "28         1\n",
      "29         1\n",
      "30         1\n",
      "The Precision for Test for the Monte Carlo iterations (for best C) is : \n",
      "    Precision Test\n",
      "1         87.8049\n",
      "2          97.561\n",
      "3         91.1111\n",
      "4          97.619\n",
      "5         97.6744\n",
      "6             100\n",
      "7         92.6829\n",
      "8         93.1818\n",
      "9            97.5\n",
      "10            100\n",
      "11        91.1111\n",
      "12        91.1111\n",
      "13        93.0233\n",
      "14        95.5556\n",
      "15            100\n",
      "16         97.619\n",
      "17            100\n",
      "18         95.122\n",
      "19        90.4762\n",
      "20        97.3684\n",
      "21        95.3488\n",
      "22        92.8571\n",
      "23        93.1818\n",
      "24        91.4894\n",
      "25         97.561\n",
      "26        91.1111\n",
      "27        84.7826\n",
      "28         97.561\n",
      "29        90.6977\n",
      "30           87.5\n",
      "The Recall for Test for the Monte Carlo iterations (for best C) is : \n",
      "    Recall Test\n",
      "1      83.7209\n",
      "2      93.0233\n",
      "3      95.3488\n",
      "4      95.3488\n",
      "5      97.6744\n",
      "6      88.3721\n",
      "7      88.3721\n",
      "8      95.3488\n",
      "9      90.6977\n",
      "10     93.0233\n",
      "11     95.3488\n",
      "12     95.3488\n",
      "13     93.0233\n",
      "14         100\n",
      "15     95.3488\n",
      "16     95.3488\n",
      "17     90.6977\n",
      "18     90.6977\n",
      "19     88.3721\n",
      "20     86.0465\n",
      "21     95.3488\n",
      "22     90.6977\n",
      "23     95.3488\n",
      "24         100\n",
      "25     93.0233\n",
      "26     95.3488\n",
      "27     90.6977\n",
      "28     93.0233\n",
      "29     90.6977\n",
      "30     97.6744\n",
      "The Accuracy for Test for the Monte Carlo iterations (for best C) is : \n",
      "    Accuracy Test\n",
      "1        89.5652\n",
      "2        96.5217\n",
      "3        94.7826\n",
      "4        97.3913\n",
      "5        98.2609\n",
      "6        95.6522\n",
      "7        93.0435\n",
      "8        95.6522\n",
      "9        95.6522\n",
      "10       97.3913\n",
      "11       94.7826\n",
      "12       94.7826\n",
      "13       94.7826\n",
      "14       98.2609\n",
      "15       98.2609\n",
      "16       97.3913\n",
      "17       96.5217\n",
      "18       94.7826\n",
      "19       92.1739\n",
      "20        93.913\n",
      "21       96.5217\n",
      "22        93.913\n",
      "23       95.6522\n",
      "24       96.5217\n",
      "25       96.5217\n",
      "26       94.7826\n",
      "27       90.4348\n",
      "28       96.5217\n",
      "29       93.0435\n",
      "30        93.913\n",
      "The F1 for Test for the Monte Carlo iterations (for best C) is : \n",
      "      F1 Test\n",
      "1   0.857143\n",
      "2   0.952381\n",
      "3   0.931818\n",
      "4   0.964706\n",
      "5   0.976744\n",
      "6   0.938272\n",
      "7   0.904762\n",
      "8   0.942529\n",
      "9   0.939759\n",
      "10  0.963855\n",
      "11  0.931818\n",
      "12  0.931818\n",
      "13  0.930233\n",
      "14  0.977273\n",
      "15   0.97619\n",
      "16  0.964706\n",
      "17   0.95122\n",
      "18  0.928571\n",
      "19  0.894118\n",
      "20   0.91358\n",
      "21  0.953488\n",
      "22  0.917647\n",
      "23  0.942529\n",
      "24  0.955556\n",
      "25  0.952381\n",
      "26  0.931818\n",
      "27  0.876404\n",
      "28  0.952381\n",
      "29  0.906977\n",
      "30  0.923077\n",
      "The test error for the Monte Carlo iterations (for best C) is : \n",
      "    Test Error for best selected C\n",
      "1                         10.4348\n",
      "2                         3.47826\n",
      "3                         5.21739\n",
      "4                          2.6087\n",
      "5                         1.73913\n",
      "6                         4.34783\n",
      "7                         6.95652\n",
      "8                         4.34783\n",
      "9                         4.34783\n",
      "10                         2.6087\n",
      "11                        5.21739\n",
      "12                        5.21739\n",
      "13                        5.21739\n",
      "14                        1.73913\n",
      "15                        1.73913\n",
      "16                         2.6087\n",
      "17                        3.47826\n",
      "18                        5.21739\n",
      "19                        7.82609\n",
      "20                        6.08696\n",
      "21                        3.47826\n",
      "22                        6.08696\n",
      "23                        4.34783\n",
      "24                        3.47826\n",
      "25                        3.47826\n",
      "26                        5.21739\n",
      "27                        9.56522\n",
      "28                        3.47826\n",
      "29                        6.95652\n",
      "30                        6.08696\n",
      "The AUC for Test for the Monte Carlo iterations (for best C) is : \n",
      "     AUC Test\n",
      "1    0.95801\n",
      "2    0.99564\n",
      "3   0.989018\n",
      "4   0.986273\n",
      "5   0.998385\n",
      "6   0.979328\n",
      "7   0.987888\n",
      "8   0.996932\n",
      "9   0.997416\n",
      "10  0.995155\n",
      "11  0.986919\n",
      "12  0.989987\n",
      "13  0.994832\n",
      "14  0.999031\n",
      "15  0.999193\n",
      "16  0.998062\n",
      "17  0.999516\n",
      "18  0.986434\n",
      "19  0.972384\n",
      "20  0.981428\n",
      "21  0.984981\n",
      "22  0.989503\n",
      "23  0.980782\n",
      "24  0.999193\n",
      "25  0.994509\n",
      "26  0.993863\n",
      "27  0.972707\n",
      "28  0.985465\n",
      "29  0.966408\n",
      "30  0.978521\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.svm import LinearSVC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  \n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "df = pd.read_csv('wdbc.csv', header = None)\n",
    "\n",
    "\n",
    "output = df.iloc[:,0]\n",
    "\n",
    "\n",
    "for i in np.arange(0,df.shape[0]):\n",
    "    if output.iloc[i] == 'B':\n",
    "        output.iloc[i] = 0\n",
    "    else:\n",
    "        output.iloc[i] = 1\n",
    "\n",
    "\n",
    "\n",
    "features = df.iloc[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "features_normal = normalize(features)\n",
    "\n",
    "\n",
    "features_normal_df = pd.DataFrame(features_normal)\n",
    "\n",
    "\n",
    "norm_whole = pd.concat([features_normal_df,output],axis=1)\n",
    "\n",
    "\n",
    "col_head = norm_whole.columns\n",
    "\n",
    "\n",
    "norm_whole.columns= ['X1','X2','X3','X4','X5','X6','X7','X8','X9','X10','X11','X12','X13','X14','X15','X16','X17','X18','X19','X20','X21','X22','X23','X24','X25','X26','X27','X28','X29','X30','y']\n",
    "\n",
    "\n",
    "norm_whole.sort_values(by=['y'],inplace=True)\n",
    "\n",
    "\n",
    "norm_whole.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "X_y_0 = norm_whole.iloc[0:357,:]\n",
    "X_y_1 = norm_whole.iloc[357:569,:]\n",
    "X_y_1.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "C_selected = pd.DataFrame(index=np.arange(1,31),columns=['Selected Penalty'])\n",
    "\n",
    "\n",
    "\n",
    "Precision_Train = pd.DataFrame(index=np.arange(1,31),columns=['Precision Train'])\n",
    "\n",
    "Recall_Train = pd.DataFrame(index=np.arange(1,31),columns=['Recall Train'])\n",
    "\n",
    "F1_Train = pd.DataFrame(index=np.arange(1,31),columns=['F1 Train'])\n",
    "\n",
    "Accuracy_Train = pd.DataFrame(index=np.arange(1,31),columns=['Accuracy Train'])\n",
    "\n",
    "AUC_Train = pd.DataFrame(index=np.arange(1,31),columns=['AUC Train'])\n",
    "\n",
    "Train_Error = pd.DataFrame(index=np.arange(1,31),columns=['Train Error for best selected C'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Precision_Test = pd.DataFrame(index=np.arange(1,31),columns=['Precision Test'])\n",
    "\n",
    "Recall_Test = pd.DataFrame(index=np.arange(1,31),columns=['Recall Test'])\n",
    "\n",
    "F1_Test = pd.DataFrame(index=np.arange(1,31),columns=['F1 Test'])\n",
    "\n",
    "Accuracy_Test = pd.DataFrame(index=np.arange(1,31),columns=['Accuracy Test'])\n",
    "\n",
    "AUC_Test = pd.DataFrame(index=np.arange(1,31),columns=['AUC Test'])\n",
    "\n",
    "Test_Error = pd.DataFrame(index=np.arange(1,31),columns=['Test Error for best selected C'])\n",
    "\n",
    "# Test_Error_Estimated does not have meaning here (as defined previously)\n",
    "# Explanation a bit lengthy but since min_C selected over labeled train, which once selected is used to estimate unlabeled train\n",
    "# the estimated test error is the estimate over the labeled train (for CV over the labeled train)\n",
    "\n",
    "# to get the test error estimate CV (5-fold/K-Fold) over final obtained X_train and y_train using selected min_C must be done\n",
    "# this for each monte-carlo iteration becomes computationally intensive, and thus hasn't been performed\n",
    "\n",
    "# additionally the most ideal way of selecting C would be cross-validating C over both labeled and unlabeled train\n",
    "# the question in HW is segmented, also this is computationally intensive\n",
    "# thus hasn't been done\n",
    "\n",
    "# in this method we'd obtain final X_train and y_train from labeled and unlabeled train for each C\n",
    "# than for that X_train, y_train and C for which that X_train and y_train was obtained, we'd CV again internally to obtain\n",
    "# the test error estimate\n",
    "# Thus there would be two cross validation loop, first to pick C and second to pick C corresponding to the lowest\n",
    "# test error estimate\n",
    "# Note all this would be inside a monte-carlo loop\n",
    "# Also the while loop, other than the two for loops (for CV), for generating X_train and y_train, can't be neglected\n",
    "# This will enormously increase the computation time\n",
    "# Additionally there may be other methods/ways also to CV over penalty in the current case\n",
    "# We've picked the least computationally intensive segmented approach as deliberated in the HW\n",
    "\n",
    "# CONCLUSION: Test Error Estimation, may be performed, differently than performed in Supervised learning, either in a sense\n",
    "# absolutely true to selection of C or in an approximate, segmented sense, both requiring much longer computational times\n",
    "# than the computational time already required for the Monte-Carlo simulation, in general, and thus the minimal approach has been \n",
    "# utilized here\n",
    "\n",
    "\n",
    "\n",
    "for mc in np.arange(0,30):\n",
    "    \n",
    "    print(mc)  # to keep tally of MC iterations\n",
    "\n",
    "    X_y_train_0,X_y_test_0 = train_test_split(X_y_0,test_size = 0.2,shuffle=True)\n",
    "    X_y_train_1,X_y_test_1 = train_test_split(X_y_1,test_size = 0.2,shuffle=True)\n",
    "\n",
    "    X_y_train_0_l, X_y_train_0_u = train_test_split(X_y_train_0,test_size = 0.5, shuffle=True) \n",
    "    X_y_train_1_l, X_y_train_1_u = train_test_split(X_y_train_1,test_size = 0.5, shuffle=True)\n",
    "\n",
    "\n",
    "    X_y_train = pd.concat([X_y_train_0_l,X_y_train_1_l],axis=0)\n",
    "    X_y_train_u = pd.concat([X_y_train_0_u,X_y_train_1_u],axis=0)\n",
    "    X_y_test = pd.concat([X_y_test_0,X_y_test_1],axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X_y_train = shuffle(X_y_train)\n",
    "    X_y_train_u = shuffle(X_y_train_u)\n",
    "    X_y_test = shuffle(X_y_test)\n",
    "\n",
    "\n",
    "\n",
    "    X_y_train.reset_index(drop=True,inplace=True)\n",
    "    X_y_train_u.reset_index(drop=True,inplace=True)\n",
    "    X_y_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "\n",
    "    X_train = X_y_train.drop(columns=['y'])\n",
    "    X_train_u = X_y_train_u.drop(columns=['y'])\n",
    "    X_test = X_y_test.drop(columns=['y'])\n",
    "    y_train = X_y_train['y'].astype(int)\n",
    "    y_train_u = X_y_train_u['y'].astype(int)\n",
    "    y_test =  X_y_test['y'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=5,shuffle=True)\n",
    "\n",
    "    C = np.array([10**(-1),10**(0),10**(1),10**(2),10**(3),10**(4),10**(5),10**(6),10**(7)]) \n",
    "\n",
    "    error_df = pd.DataFrame(index = C, columns = ['Estimated Test Errors'])\n",
    "\n",
    "    for i in np.arange(0,C.size):\n",
    "\n",
    "        cv_ite = -1\n",
    "        cv_error_vector = np.zeros(5)  \n",
    "\n",
    "        for train,test in kf.split(X_train):\n",
    "\n",
    "            cv_ite = cv_ite + 1  \n",
    "            X_train_cv,X_test_cv = X_train.iloc[train,:],X_train.iloc[test,:]\n",
    "            y_train_cv,y_test_cv = y_train[train],y_train[test]\n",
    "            clf = LinearSVC(penalty='l1',dual=False,C=C[i]).fit(X_train_cv,y_train_cv)\n",
    "            y_test_cv_pred = clf.predict(X_test_cv)\n",
    "\n",
    "            mis = 0\n",
    "            for l in np.arange(0,X_test_cv.shape[0]):\n",
    "                if y_test_cv_pred[l] != y_test_cv.iloc[l]:\n",
    "                    mis = mis + 1\n",
    "\n",
    "            percent_error = (mis/X_test_cv.shape[0])*100\n",
    "            cv_error_vector[cv_ite] = percent_error\n",
    "\n",
    "\n",
    "        error_df.iloc[i,0] = np.mean(cv_error_vector)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    min_error = np.min(error_df.to_numpy().flatten())\n",
    "    min_C = C[np.argmin(error_df.to_numpy().flatten())]\n",
    "    \n",
    "    C_selected.iloc[mc,0] = min_C\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X_train_O = X_train.copy()\n",
    "    y_train_O = y_train.copy()\n",
    "    X_train_u_O = X_train_u.copy()\n",
    "    y_train_u_O = y_train_u.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    unlabel_length = X_train_u.shape[0]\n",
    "\n",
    "\n",
    "    while unlabel_length > 0:\n",
    "\n",
    "        clf_u = LinearSVC(penalty='l1',dual=False,C=min_C).fit(X_train,y_train)   \n",
    "        y_train_u_pred = clf_u.predict(X_train_u)\n",
    "        X_train_u_decision_function = clf_u.decision_function(X_train_u)    \n",
    "        X_train_u_distance = abs(X_train_u_decision_function)               \n",
    "        unlab_samp_selec_indx = np.argmax(X_train_u_distance)              \n",
    "        unlab_samp_selec = X_train_u.iloc[unlab_samp_selec_indx,:].to_numpy().reshape(1,X_train_u.shape[1])\n",
    "        unlab_samp_selec_df = pd.DataFrame(unlab_samp_selec, columns=X_train_u.columns)\n",
    "        y_unlab_samp_selec = y_train_u_pred[unlab_samp_selec_indx] \n",
    "        X_train = pd.concat([X_train,unlab_samp_selec_df],axis=0)\n",
    "        X_train.reset_index(drop=True,inplace=True)       \n",
    "        y_train[y_train.size] = y_unlab_samp_selec        \n",
    "        indx_interim = np.arange(0,X_train_u.shape[0])\n",
    "        indx_selected = np.delete(indx_interim,unlab_samp_selec_indx)\n",
    "\n",
    "        X_train_u = X_train_u.iloc[indx_selected,:]\n",
    "        X_train_u.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        y_train_u = y_train_u.iloc[indx_selected]          \n",
    "        y_train_u.reset_index(drop=True,inplace=True)      \n",
    "\n",
    "        unlabel_length = X_train_u.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    clf_final = LinearSVC(penalty='l1',dual=False,C=min_C).fit(X_train,y_train)\n",
    "    y_test_pred = clf_final.predict(X_test)\n",
    "\n",
    "    mis = 0\n",
    "    for l in np.arange(0,X_test.shape[0]):\n",
    "        if y_test_pred[l] != y_test.iloc[l]:\n",
    "            mis = mis + 1\n",
    "\n",
    "    test_error = (mis/X_test.shape[0])*100\n",
    "    \n",
    "    Test_Error.iloc[mc,0] = test_error\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    y_train_pred = clf_final.predict(X_train)\n",
    "\n",
    "    mis = 0\n",
    "    for l in np.arange(0,X_train.shape[0]):\n",
    "        if y_train_pred[l] != y_train.iloc[l]:\n",
    "            mis = mis + 1\n",
    "\n",
    "    train_error = (mis/X_train.shape[0])*100\n",
    "    \n",
    "    Train_Error.iloc[mc,0] = train_error\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    confusion_matrix_train = confusion_matrix(y_train,y_train_pred)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    confusion_matrix_train_df = pd.DataFrame(confusion_matrix_train,index=['Actually 0','Actually 1'],columns=['Predicted 0','Predicted 1'])\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    precision_train = (confusion_matrix_train[1][1]/(confusion_matrix_train[1][1]+confusion_matrix_train[0][1]))*100\n",
    "    recall_train = (confusion_matrix_train[1][1]/(confusion_matrix_train[1][1]+confusion_matrix_train[1][0]))*100\n",
    "\n",
    "    Precision_Train.iloc[mc,0] = precision_train\n",
    "    Recall_Train.iloc[mc,0] = recall_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    accuracy_train = ((confusion_matrix_train[0][0]+confusion_matrix_train[1][1])/(confusion_matrix_train[0][0]+confusion_matrix_train[1][1]+confusion_matrix_train[0][1]+confusion_matrix_train[1][0]))*100\n",
    "    f1_train = ((2*(precision_train/100)*(recall_train/100))/((precision_train/100)+(recall_train/100))) # divided by 100 as precision and recall specified in percentage\n",
    "    \n",
    "    Accuracy_Train.iloc[mc,0] = accuracy_train\n",
    "    F1_Train.iloc[mc,0] = f1_train\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    confusion_matrix_test = confusion_matrix(y_test,y_test_pred)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    confusion_matrix_test_df = pd.DataFrame(confusion_matrix_test,index=['Actually 0','Actually 1'],columns=['Predicted 0','Predicted 1'])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    precision_test = (confusion_matrix_test[1][1]/(confusion_matrix_test[1][1]+confusion_matrix_test[0][1]))*100\n",
    "    recall_test = (confusion_matrix_test[1][1]/(confusion_matrix_test[1][1]+confusion_matrix_test[1][0]))*100\n",
    "\n",
    "    Precision_Test.iloc[mc,0] = precision_test\n",
    "    Recall_Test.iloc[mc,0] = recall_test\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    accuracy_test = ((confusion_matrix_test[0][0]+confusion_matrix_test[1][1])/(confusion_matrix_test[0][0]+confusion_matrix_test[1][1]+confusion_matrix_test[0][1]+confusion_matrix_test[1][0]))*100\n",
    "    f1_test = ((2*(precision_test/100)*(recall_test/100))/((precision_test/100)+(recall_test/100))) # divided by 100 as precision and recall specified in percentage\n",
    "    \n",
    "    Accuracy_Test.iloc[mc,0] = accuracy_test\n",
    "    F1_Test.iloc[mc,0] = f1_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    clf_prob = LinearSVC(penalty='l1',dual=False,C=min_C)\n",
    "    calibrated_svc = CalibratedClassifierCV(clf_prob,method='sigmoid')\n",
    "    calibrated_svc.fit(X_train,y_train)\n",
    "    y_train_pred_prob = calibrated_svc.predict_proba(X_train)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    y_train_pred_prob_0 = y_train_pred_prob[:,0]\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    thresh = np.arange(0,1.01,0.01)\n",
    "    ROC_df = pd.DataFrame(index=thresh,columns=['FPR','TPR'])\n",
    "    for i in np.arange(0,thresh.size):\n",
    "        y_train_pred_roc = (y_train_pred_prob_0 <= thresh[i]).astype(int)\n",
    "        confusion_matrix_train_roc = confusion_matrix(y_train,y_train_pred_roc)\n",
    "        ROC_df.iloc[i,0] = confusion_matrix_train_roc[0][1]/(confusion_matrix_train_roc[0][1]+confusion_matrix_train_roc[0][0])\n",
    "        ROC_df.iloc[i,1] = confusion_matrix_train_roc[1][1]/(confusion_matrix_train_roc[1][1]+confusion_matrix_train_roc[1][0])\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    AUC_train = metrics.auc(ROC_df['FPR'],ROC_df['TPR'])\n",
    "    \n",
    "    AUC_Train.iloc[mc,0] = AUC_train \n",
    "\n",
    "\n",
    "    y_test_pred_prob = calibrated_svc.predict_proba(X_test)\n",
    "    y_test_pred_prob_0 = y_test_pred_prob[:,0]\n",
    "   \n",
    "\n",
    "\n",
    "    thresh = np.arange(0,1.01,0.01)\n",
    "    ROC_df_test = pd.DataFrame(index=thresh,columns=['FPR','TPR'])\n",
    "    for i in np.arange(0,thresh.size):\n",
    "        y_test_pred_roc = (y_test_pred_prob_0 <= thresh[i]).astype(int)\n",
    "        confusion_matrix_test_roc = confusion_matrix(y_test,y_test_pred_roc)\n",
    "        ROC_df_test.iloc[i,0] = confusion_matrix_test_roc[0][1]/(confusion_matrix_test_roc[0][1]+confusion_matrix_test_roc[0][0])\n",
    "        ROC_df_test.iloc[i,1] = confusion_matrix_test_roc[1][1]/(confusion_matrix_test_roc[1][1]+confusion_matrix_test_roc[1][0])\n",
    "   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    AUC_test = metrics.auc(ROC_df_test['FPR'],ROC_df_test['TPR'])\n",
    "    \n",
    "    AUC_Test.iloc[mc,0] = AUC_test\n",
    "    \n",
    "    \n",
    "    \n",
    "print('The best C, penalty, selected for each Monte Carlo iterations is :\\n',C_selected)\n",
    "    \n",
    "print('The Precision for Train for the Monte Carlo iterations (for best C) is : \\n',Precision_Train)\n",
    "print('The Recall for Train for the Monte Carlo iterations (for best C) is : \\n',Recall_Train)\n",
    "print('The Accuracy for Train for the Monte Carlo iterations (for best C) is : \\n',Accuracy_Train)\n",
    "print('The F1 for Train for the Monte Carlo iterations (for best C) is : \\n',F1_Train)\n",
    "print('The training error for the Monte Carlo iterations (for best C) is : \\n',Train_Error)\n",
    "print('The AUC for Train for the Monte Carlo iterations (for best C) is : \\n',AUC_Train)\n",
    "\n",
    "\n",
    "\n",
    "print('The Precision for Test for the Monte Carlo iterations (for best C) is : \\n',Precision_Test)\n",
    "print('The Recall for Test for the Monte Carlo iterations (for best C) is : \\n',Recall_Test)\n",
    "print('The Accuracy for Test for the Monte Carlo iterations (for best C) is : \\n',Accuracy_Test)\n",
    "print('The F1 for Test for the Monte Carlo iterations (for best C) is : \\n',F1_Test)\n",
    "print('The test error for the Monte Carlo iterations (for best C) is : \\n',Test_Error)\n",
    "print('The AUC for Test for the Monte Carlo iterations (for best C) is : \\n',AUC_Test)\n",
    "\n",
    "# Test error estimation not done due to computational limitations and run time constraints. See upper comment explanations\n",
    "# for detailed description\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR TRAIN \n",
      "\n",
      "\n",
      "The overall train precision is : \n",
      " 99.70514050987488 %\n",
      "\n",
      "The overall train recall is : \n",
      " 99.3680658684955 %\n",
      "\n",
      "The overall train accuracy is : \n",
      " 99.65491923641707 %\n",
      "\n",
      "The overall train F1 is : \n",
      " 0.9953562318215182\n",
      "\n",
      "The overall train AUC is : \n",
      " 0.9997362293288456\n",
      "\n",
      "The overall train error is : \n",
      " 0.3450807635829662 %\n",
      "\n",
      "FOR TEST \n",
      "\n",
      "\n",
      "The overall test precision is : \n",
      " 94.28707751196056 %\n",
      "\n",
      "The overall test recall is : \n",
      " 93.10077519379844 %\n",
      "\n",
      "The overall test accuracy is : \n",
      " 95.24637681159422 %\n",
      "\n",
      "The overall test F1 is : \n",
      " 0.9361251191855166\n",
      "\n",
      "The overall test AUC is : \n",
      " 0.9879252799310939\n",
      "\n",
      "The overall test error is : \n",
      " 4.753623188405797 %\n",
      "\n",
      "The overall value of penalty selected is : \n",
      " 10000.0\n",
      "\n",
      "NOTE : All this has been averaged over 30 Monte-Carlo Trials, with train and test selected randomly \n",
      "\n",
      "\n",
      "NOTE : For Penalty, instead of average, mode has been used as measure of central tendency over Monte Carlo iterations \n",
      "\n",
      "\n",
      "NOTE : All the above values are, obviously, averaged over the best selected C in each case (in each Monte Carlo iteration) \n",
      "\n",
      "\n",
      "NOTE : All values except C (penalty), F1 Score, AUC are in %\n"
     ]
    }
   ],
   "source": [
    "ovrl_precision_train = Precision_Train.mean(axis=0)\n",
    "ovrl_recall_train = Recall_Train.mean(axis=0)\n",
    "ovrl_accuracy_train = Accuracy_Train.mean(axis=0)\n",
    "ovrl_F1_train = F1_Train.mean(axis=0)\n",
    "ovrl_auc_train = AUC_Train.mean(axis=0)\n",
    "ovrl_train_error = Train_Error.mean(axis=0)\n",
    "\n",
    "\n",
    "ovrl_precision_test = Precision_Test.mean(axis=0)\n",
    "ovrl_recall_test = Recall_Test.mean(axis=0)\n",
    "ovrl_accuracy_test = Accuracy_Test.mean(axis=0)\n",
    "ovrl_F1_test = F1_Test.mean(axis=0)\n",
    "ovrl_auc_test = AUC_Test.mean(axis=0)\n",
    "ovrl_test_error = Test_Error.mean(axis=0)\n",
    "\n",
    "\n",
    "\n",
    "ovrl_C_selected = C_selected.mode(axis=0)\n",
    "\n",
    "\n",
    "print('FOR TRAIN \\n')\n",
    "\n",
    "print('\\nThe overall train precision is : \\n',pd.DataFrame(ovrl_precision_train).iloc[0,0],'%')\n",
    "print('\\nThe overall train recall is : \\n',pd.DataFrame(ovrl_recall_train).iloc[0,0],'%')\n",
    "print('\\nThe overall train accuracy is : \\n',pd.DataFrame(ovrl_accuracy_train).iloc[0,0],'%')\n",
    "print('\\nThe overall train F1 is : \\n',pd.DataFrame(ovrl_F1_train).iloc[0,0])\n",
    "print('\\nThe overall train AUC is : \\n',pd.DataFrame(ovrl_auc_train).iloc[0,0])\n",
    "print('\\nThe overall train error is : \\n',pd.DataFrame(ovrl_train_error).iloc[0,0],'%')\n",
    "\n",
    "print('\\nFOR TEST \\n')\n",
    "\n",
    "print('\\nThe overall test precision is : \\n',pd.DataFrame(ovrl_precision_test).iloc[0,0],'%')\n",
    "print('\\nThe overall test recall is : \\n',pd.DataFrame(ovrl_recall_test).iloc[0,0],'%')\n",
    "print('\\nThe overall test accuracy is : \\n',pd.DataFrame(ovrl_accuracy_test).iloc[0,0],'%')\n",
    "print('\\nThe overall test F1 is : \\n',pd.DataFrame(ovrl_F1_test).iloc[0,0])\n",
    "print('\\nThe overall test AUC is : \\n',pd.DataFrame(ovrl_auc_test).iloc[0,0])\n",
    "print('\\nThe overall test error is : \\n',pd.DataFrame(ovrl_test_error).iloc[0,0],'%')\n",
    "\n",
    "\n",
    "\n",
    "print('\\nThe overall value of penalty selected is : \\n',pd.DataFrame(ovrl_C_selected).iloc[0,0])\n",
    "\n",
    "\n",
    "print('\\nNOTE : All this has been averaged over 30 Monte-Carlo Trials, with train and test selected randomly \\n')\n",
    "print('\\nNOTE : For Penalty, instead of average, mode has been used as measure of central tendency over Monte Carlo iterations \\n')\n",
    "print('\\nNOTE : All the above values are, obviously, averaged over the best selected C in each case (in each Monte Carlo iteration) \\n')\n",
    "print('\\nNOTE : All values except C (penalty), F1 Score, AUC are in %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test error estimation not done see explanations in comments\n",
    "\n",
    "Rest all results for Semi-Supervised learning as seen above in the relevant dataframes and also, subsequently, averaged\n",
    "\n",
    "Conclusion for all methods, once, all have been run"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
